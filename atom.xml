<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>阿吉的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="/"/>
  <updated>2020-01-20T17:19:57.738Z</updated>
  <id>/</id>
  
  <author>
    <name>Jim Lin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2019 年度总结</title>
    <link href="/2020/01/21/2019-%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    <id>/2020/01/21/2019-年度总结/</id>
    <published>2020-01-20T16:04:35.000Z</published>
    <updated>2020-01-20T17:19:57.738Z</updated>
    
    <content type="html"><![CDATA[<p>2018 年的主题是独立, 我有了第一份正经工作, 自己养活了自己. 今天回顾 2019, 我觉得这是成长的一年, 各种意义上的.</p><a id="more"></a><h3 id="待人处事"><a href="#待人处事" class="headerlink" title="待人处事"></a>待人处事</h3><p>我之前在知乎有个账号叫&quot;林诚&quot;, 用了好多年了, 一开始是因为这是父母的姓合起来, 顺手就起了这么个网名, 渐渐就觉得这个名字很好. 我自己虽然做不到完全诚实, 但真心觉得诚实是美好的品质, 希望自己以后都尽量真诚待人. 认识了一位网友, 双方都做了很过分的事情, 在互相伤害升级的过程中, 事情对我来说就有些不可收拾了. Ta 知道我的大部分信息, 但我对 Ta 接近于一无所知. 我删了账号, 一是避风头, 二也是摇尾乞怜吧. Ta 最后还是放了我一马, 谢谢~ 那一周, 我是真的感受到了如芒在背, 甚至有些精神崩溃.</p><p>如果我在与人交往时小心一点, 谨慎一点, 敏感的信息不说, 是不是会更好过一些呢? 所以我目前的账号叫&quot;林谨&quot;. 希望自己常怀善意的同时, 也要提防恶意吧. 那么, 我现在把这一段往事翻出来, 是不是不谨慎呢? 我想大抵是没事儿的. 我在最最崩溃的时候, 晚上怎么也睡不着, 冬天大半夜的跑去跟警察叔叔聊了会儿天, 原来整件事情其实还在可控范围内, 唠了唠家常, 我就回家睡觉了. 我要感谢 Ta, 让我明白什么叫做有心机与此同时也让我明白什么叫做精神依赖. 带毒的鲜花也很美呀~ 人真的是复杂的动物.</p><h3 id="陈粒-许嵩"><a href="#陈粒-许嵩" class="headerlink" title="陈粒 / 许嵩"></a>陈粒 / 许嵩</h3><p>在工作之前, 我其实是很单调的, 每天就是写代码看资料. 工作之后, 烦心的事情多了, 下班之后, 累得再也学不动了, 就会开始听听歌, 看看国产剧. 我第一次听到陈粒的歌是应该是&quot;自渡&quot;. 歌词空灵得一匹, 以至于我现在也不是很明白. 但那句&quot;常唤不醒错过风雨人潮, 青苔斑驳闻讯而不知晓&quot;, 真的命中我了. 我是真的错过了很多风雨人潮, T_T. 有段时间天天就听陈粒, 好喜欢她的歌词品位啊! 陈雪凝的歌词要是有陈粒的一半美感就好了... 比如那句&quot;我怎会把死守的寂寞, 放任了&quot;? 嗯? 不能含蓄点吗? 白瞎了旋律还是挺好哒. 00 后的小妹妹不能要求太多啦. 除了计算机, 意识到其实这个世界还有很多好玩的. 这也算一种成长吧?</p><p>6 月的时候去了趟许嵩的北京演唱会, 现场气氛超好的!!! 许嵩风靡我的高中时代, 工作了, 支持他下, 也算缅怀了下我的青春. 许嵩真的是没有黑点, 没节奏, 就安安心心做音乐, 还很好听, 实在是不能不让人喜欢. 2020 年, 许嵩应该是没演唱会了, 那希望能现场听陈粒~</p><h3 id="技术成长"><a href="#技术成长" class="headerlink" title="技术成长"></a>技术成长</h3><p>8 月份的时候跳槽了. 有句话怎么说, 见识到了更大的世界. 新的工作时有更多的挑战与机遇. 在此客套下, 感谢前雇主的培养与现在雇主的赏识, 哈哈. 我真正有机会接触到先进的技术与优秀的人共事. 最近面了几个老哥, 很多人干了很多年, 其实技能还停留在三年的水准, 这是环境限制了. 几百台服务器的规模需要真正硬核的技术吗? 能把业务方案实施了就万事大吉了. 在此规模上上, 翻个一千倍, 事情就有意思多了. 我目前做的项目在国内还是领先的吧, 暂时保密. 如果能做成, 那将会是我职业生涯的第一个 milestone~ 我真的花了很多心血, 也不怕在这里立 flag. 我对我有自信, 无惧挑战!</p><h3 id="2020"><a href="#2020" class="headerlink" title="2020"></a>2020</h3><p>不要像今年这么拼, 多花点时间休息, 培养些爱好.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2018 年的主题是独立, 我有了第一份正经工作, 自己养活了自己. 今天回顾 2019, 我觉得这是成长的一年, 各种意义上的.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>mm_prefetch 与 mm_pause</title>
    <link href="/2019/10/08/mm-prefetch-%E4%B8%8E-mm-pause/"/>
    <id>/2019/10/08/mm-prefetch-与-mm-pause/</id>
    <published>2019-10-07T17:25:41.000Z</published>
    <updated>2019-10-08T16:15:03.878Z</updated>
    
    <content type="html"><![CDATA[<p>十一假期的最后一天的晚上睡不着, 才又想起了博客君... 这次要写的是 X86 的 mm_prefetch 和 mm_pause 指令. 这两个指令有共性也有相反的地方, 所以放在一起特别合适. 因为个人习惯, mm_prefetch 指令指使用 intrinsics 头文件后会生成的指令, mm_pause 指令同理.</p><a id="more"></a><h2 id="mm-prefetch-与-mm-pause-的简单介绍"><a href="#mm-prefetch-与-mm-pause-的简单介绍" class="headerlink" title="mm_prefetch 与 mm_pause 的简单介绍"></a>mm_prefetch 与 mm_pause 的简单介绍</h2><p>mm_prefetch 和 mm_pause 都对于程序的正确性没有影响且对于 CPU 理论上只是一个 hint.</p><p>mm_prefetch 提示 CPU 要去预读取某些内存地址的内容到缓存中, 一般来说会拉一个 cache line(64B).</p><p>mm_pause 提示 CPU 要空转一会儿, 一般用于多核多线程场景下. 比如, 吃饭之前要做饭, 吃饭的人就必须等待做饭的人把饭做好才能吃, 等待这个动作就是 mm_pause 的功能.</p><p>可见以上两个指令是比较安全的, 但也不能滥用, 那么什么场景下最适合, 什么场景不能用呢?</p><h2 id="mm-prefetch"><a href="#mm-prefetch" class="headerlink" title="mm_prefetch"></a>mm_prefetch</h2><p>内存的延迟高达 70ns - 80ns, 一颗 2GHz 的处理器可以跑 140 - 160 个周期了. 这有多夸张呢? 一条 cache miss 的 MOV 指令顶得上一百多条普通的加法减法命令了... 根据我实际的工程经验来看, 30% - 50% 的索引数据结构的耗时都在访问内存上. perf 中一看到单个函数内耗时 80% 的指令 99% 都是 MOV. 这个锅主要光速要背. 光 1us 只能跑 300 米左右, 1ns 只能跑 30厘米, 从 CPU 到内存那么多电路, 必然快不了.</p><p>那很自然的想法就是预读, 计算的时候后台拉内存, 还用吃饭的比方就是, 我在写代码的时候, 食堂已经在做饭了. CPU 就是这么做的, 这个叫 Hardware Prefetcher. CPU 会看有哪些 MOV 指令可以先做的, 就尽量做.</p><p>那为啥还要有 mm_prefetch 呢? 其实可以反问的是既然都有硬件预读器了, 为啥索引数据结构还有大量时间花在内存访问上呢? 因为显而易见的预读机会是不那么多的. 人一到点就吃饭, 这是一个规律的事件. 所以食堂大厨可以提前准备. 卖雨伞的摊贩就很难提前准备了. 这时候就有了软件预读, 也就是 mm_prefetch 指令. 程序员相比 CPU 有更详细的程序上下文信息来提前判断哪些内存可能会被用到.</p><p>如果只是科普下软件预读, 就很无聊了. 我在实践中发现 mm_prefetch 要起作用比想象中的难!</p><p>首先, 硬件预读已经能把显而易见的预读做完了, 到 pref 时发现 stall 的地方可能根本就不存在优化空间. 因为整个逻辑就是强前后相关的, 先种瓜才能得瓜.</p><p>其次, 由于硬件预读的逻辑不对程序员暴露, 加之现代处理器的黑科技特别多, 你很难 reason 每条指令究竟对整体运行时间有什么影响, 优化变成了排列组合然后编译运行计时的体力活.</p><p>想象有以下代码,</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> total = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    total += some_data[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我一开始想在 <code>total += some_data[i]</code> 时, 去预读 <code>some_data[i+1]</code> 会加速, 但现实是更慢了. 因为 CPU 太聪明了, 通过分支预测器, 它能大概率推断出执行完加法操作后, 会需要 <code>some_data[i+1]</code>, 从而让硬件预读器做了预读, 这时候 mm_prefetch 就是废指令.</p><p>最后, 错误的 prefetch 会污染缓存, 把有用的数据逐出. 这个很好理解就不赘述了.</p><p>我总结出来的经验是不要把自己想得太聪明, 把处理器想得太笨. 比较稳妥的优化方案是找出因为 cache miss 而 stall 的点, 利用这个 stall 的时间做一些有用的事情而不是单纯想着消除这个 stall. 比如在 stall 点 A, 既然消除不了 A 的 stall, 那么我是不是可以在 A 点做一些计算? 拉内存不影响 CPU 做纯计算(在一定条件下). 这是废时间再利用策略, 我觉得很简单有效. 因为处理器都没辙了, 那些空闲的电路不用白不用.</p><h3 id="mm-prefetch-与软件超线程"><a href="#mm-prefetch-与软件超线程" class="headerlink" title="mm_prefetch 与软件超线程"></a>mm_prefetch 与软件超线程</h3><p>这是 mm_prefetch 的高阶用法, 但实用价值有限, 所以单独摘出来写, 权当开拓思路了. 超线程的实现机制简单说就是一个核心上面有两组一模一样的寄存器但共享计算单元(和一些别的单元), 这样对外暴露是多个核的样子. 一旦有一个核发生了 cache miss 或者别的 stall, 通过硬件电路在 ns 级别切换到这个核上的另一组寄存器, 那个寄存器下的工作就可以继续, 充分利用 CPU 上的空闲单元.</p><p>但一般来说, 每个核只有 2 个超线程. 如果 cache miss 很严重, 那每个核配备的超线程就应该更多, 反之如果基本没啥 cache miss, 超线程基本就是浪费. 由于硬件是改不了的, 所以只能折中, 选了个大多数情况下都不会差的每个核 2 个超线程.</p><p>其实软件是可以模拟超线程的, 一旦遇到了大概率会 cache miss 的点, 先用 mm_prefetch 预读, 然后执行下一个任务, 执行了一些任务后, 回到最初的那个任务, 大概率预读器也把内存读到缓存了, 继续执行, 没有 stall, 整体流程与硬件超线程类似. 不同点在于软件层面的超线程, 可以做到单核 8 线程的效果, 甚至做成单核 100 线程也没人拦着. 这个模型和协程非常契合.</p><p>C++ 17 还没真正高性能的协程, 我用手写的状态机模拟了协程. 之前 Get 一次做一个操作, 现在改成 MultiGet, 一次拉 10 条, 等于有 10 个状态机, 来回轮转. 最后性能提升了令人震惊的 25%! 这个函数本来就高度优化了, 这真是在牙缝里扣的性能了.</p><p>效果那么好, 但为啥又说价值不高呢? 因为这要求调用方采用 MultiGet 而非 Get. 为了 25% 的性能提升而大改编程接口, 我觉得有点难...</p><h3 id="mm-prefetch-的一点小瑕疵"><a href="#mm-prefetch-的一点小瑕疵" class="headerlink" title="mm_prefetch 的一点小瑕疵"></a>mm_prefetch 的一点小瑕疵</h3><p>mm_prefetch 严格来说是和硬件超线程冲突的, 因为硬件超线程就是解决 cache miss 的. 我个人在多线程数据结构的情况下, 一般不用 mm_prefetch.</p><h2 id="mm-pause"><a href="#mm-pause" class="headerlink" title="mm_pause"></a>mm_pause</h2><p>mm_pause 是为多核多线程而生的指令, 简单说就是让 CPU 啥也不干. 但为啥这会对性能有好处呢?</p><ul><li>现代处理器有流水线和分支预测, 在 spin lock 的加锁过程中, 分支预测器会被训练成傻逼, 同时大量垃圾微指令塞满流水线.</li></ul><p>想象如下场景,</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!some_atomic_var.compare_exchange_weak(a, b)) &#123;&#125;</span><br></pre></td></tr></table></figure><p>如果这个 <code>some_atomic_var</code> 一段时间内加锁不成功的话, 分支预测器会认定这个 loop 总是失败的, 这其实没有任何意义! 因为就算预测成功了, 也没有任何有意义的指令能够执行, 只能不断的 jump, jump, jump...</p><p>CPU 在硬件层面还会 unroll loop, 然后一大堆 unroll 完的垃圾微指令堆满流水线.</p><p>最好的策略是 CPU 啥也别干就老老实实等一会儿, 然后尝试 CAS 原子变量就好了.</p><ul><li>回退本身就能提高系统的吞吐</li></ul><p>10 个核 CAS 一个 bool 和 100 个核 CAS 一个 bool 在硬件层面显然前者更简单, 起码只 invalid 9 个 cache line 呢.</p><ul><li>mm_pause 可以让出资源给别的超线程</li></ul><p>这是我从 folly 文档看来的, 原理上很容易理解, spin 的等待跟 cache miss 的 stall 差不多都是废时间.</p><p>我实践中的结果是 mm_pause 可以显著降低 spin 的次数, 之前要 spin 200 万次, 用了 mm_pause 之后就 20 万次左右, 但没有观察到显著的性能提升. 我推测是因为良好工况下, 多 spin 几次对于 CPU 来说不是不可接受的.</p><p>mm_pause 会让系统变稳定很多! 这个我没有算什么方差, 标准差, 不过可以明显感觉出来. 我的 bench 一般 6 秒能跑完, 但有概率会跑到 9 秒, 用了 mm_pause 大部分情况下都能在 7 秒内完成.</p><p>总之, 我认为 spin lock 都应该用 mm_pause.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;十一假期的最后一天的晚上睡不着, 才又想起了博客君... 这次要写的是 X86 的 mm_prefetch 和 mm_pause 指令. 这两个指令有共性也有相反的地方, 所以放在一起特别合适. 因为个人习惯, mm_prefetch 指令指使用 intrinsics 头文件后会生成的指令, mm_pause 指令同理.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Go Plan9 汇编与 Intel TSX 指令集</title>
    <link href="/2019/07/21/Go-Plan9-%E6%B1%87%E7%BC%96%E4%B8%8E-Intel-TSX-%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    <id>/2019/07/21/Go-Plan9-汇编与-Intel-TSX-指令集/</id>
    <published>2019-07-21T11:16:42.000Z</published>
    <updated>2019-10-07T17:21:45.161Z</updated>
    
    <content type="html"><![CDATA[<p>博客断更好久了, 说好的每周一篇呢? 我发现精力有限(主要是懒), 尽量每月一篇吧. 我近期觉得比较有趣的事情有两件, 一是尝试了把 Go 坑爹的 Plan9 汇编, 二是简单测试了下 Intel TSX 指令集.</p><a id="more"></a><h3 id="Go-Plan9-汇编"><a href="#Go-Plan9-汇编" class="headerlink" title="Go Plan9 汇编"></a>Go Plan9 汇编</h3><p>说实话, 我不是很懂 Go 为什么要特立独行自己搞一套指令集(或者说 IR). 大抵 Go 的设计哲学就是遇到复杂问题的时候, 头埋沙子里, 选一个最&quot;大道至简&quot;的解决方案吧. Plan9 汇编既没有 LLVM IR 底层, 又没有 Java Bytecode 跨平台. 以我粗浅的理解就是把一些通用的指令做了一把重命名, 比如 MOV 之类的, 然后 calling convention, 寄存器命名和 x86 不同. 作为对比, 标准 jar 包是可以在标准 JVM 实现上跑的, LLVM IR 是不会阻碍上层应用压榨下层硬件性能的. Plan9 可能就是让人看上去很解耦吧.</p><p>我测试了在 Go 上使用 SSE 4.2 的 minpos 指令. 如果单位时间内进行一次操作得分为 1 的话, minpos 一次可以处理 4 条数据, 理论得分应该是 4. C++ 版本轻松达到了理论值, Go 只有理论值的 1/2. 我看了 C++ 和 Go 的 binary 的汇编, C++ 直接进行了函数内联, 而 Go 没有. Go 只会内联很简单的函数, 包含手写的汇编的函数不在此列. 每一次用 Go 调用 minpos 都有一次 function call 的开销, 再加上 Go 是用栈传值而非寄存器, 会进一步加大性能损失.</p><p>Go 之所以不内联带汇编的函数, 我认为也和 Plan9 有关. 因为 Plan9 不是直接面向机器的, Plan9 的寄存器分配不是机器码层级的寄存器分配, 所以一旦用了手写汇编, Go 将无法分析指令间的关系. x86 SIMD 在 Plan9 里是直接写机器码的, 对 Go 来说这就是黑盒, 什么幺蛾子都可能发生.</p><p>总结,</p><ol><li><p>高性能计算, 如非必要, 请用 C++</p></li><li><p>一定要用 Go 计算, 请不要写小段的汇编来回调, 应该直接用汇编实现一个大功能, 比如 CRC</p></li></ol><h3 id="Intel-TSX-指令集"><a href="#Intel-TSX-指令集" class="headerlink" title="Intel TSX 指令集"></a>Intel TSX 指令集</h3><p>Transactional Memory 是把数据库的事务的概念引入内存, 一连串的操作要么全部成功, 要么全部失败, 不存在中间态. 为什么直接用硬件处理很合理呢? 因为硬件可以以最小粒度来分析事件依赖. 假设, 我是一个头脑简单的程序员, 我很可能直接一把大锁锁全家, 但在硬件层面来看, 只有一个 cache line 的数据是存在竞争的. 那为啥不直接把判断竞争的任务下推?</p><p>我几年前第一次听到这个概念的时候觉得这真是革命性的! 因为它听上去很是有道理, 就好像电视购物一定会强调因为没有中间商赚差价, 所以价格便宜. 但是想想看都知道这要实现会很复杂... 根据 YouTube 上的资源, Intel 的实现方式是用 L1 cache 的 bitmap 跟踪记录读集和写集, 遇到冲突则操作失败, 修改就不会推到下层的总线写回内存. Intel 推出 TSX 指令集后, 因为有 bug, 直接用微码 patch 把这个功能禁用了... 然后修吧修吧, 又有安全问题... 内核要打性能退化补丁...</p><p>不断修修补补, 在 9 代处理上似乎稳定了. 我恰好有 9600k, 就测试了一把性能. 代码可见于 <a href="https://gist.github.com/JimChengLin/5ff29292bac4c1ec4bf00078f47725a8" target="_blank" rel="noopener">https://gist.github.com/JimChengLin/5ff29292bac4c1ec4bf00078f47725a8</a>. 就结果来看不是很理想, 但也要看怎么比.</p><p>以修改双向链表为例, 单线程 1000000 次操作大概耗时 300ms, 双线程加 TSX 加持要花 900 ms. 核多花了一倍, 性能只有 1/3. 这个其实挺符合逻辑, 巧妇难为无米之炊, 事务本身就是加锁的另一种形式而已. 如果争抢很严重, 性能最优就是单线程.</p><p>TSX 指令集最大的意义在于它让不可能成为了可能, 无锁双向链表在我看来基本是不可能的. TSX 指令集做到了这一点. 看我的代码会发现我的 TSX 版代码非常非常简单. 后面, 我写了大概半小时的 fine grained locking 版本的双向链表, 还没写对 T_T.</p><p>总结,</p><ol><li><p>如果非要用无锁, 但那个数据结构没有对应的无锁版本, 可以考虑使用 TSX</p></li><li><p>如果 contention 非常小, 基本上就是一个单写多读的场景, 可以考虑使用 TSX</p></li><li><p>如果真的很懒, 懒得处理糟心的死锁, 可以考虑使用 TSX</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;博客断更好久了, 说好的每周一篇呢? 我发现精力有限(主要是懒), 尽量每月一篇吧. 我近期觉得比较有趣的事情有两件, 一是尝试了把 Go 坑爹的 Plan9 汇编, 二是简单测试了下 Intel TSX 指令集.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>KV 存储引擎</title>
    <link href="/2019/05/12/KV-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
    <id>/2019/05/12/KV-存储引擎/</id>
    <published>2019-05-12T09:57:35.000Z</published>
    <updated>2019-10-07T18:17:40.366Z</updated>
    
    <content type="html"><![CDATA[<p>我这个周末都在被高等数学支配的恐惧中度过, (ノへ￣、) 写一篇我擅长方面的博文放松下, 希望能保持每周一更的频率. 什么 InnoDB, WiredTiger, LevelDB, RocksDB, 相关的文章有很多, 但为什么这些设计有道理呢? 我没有发现一篇讲得很明白.</p><a id="more"></a><h2 id="存储引擎是什么"><a href="#存储引擎是什么" class="headerlink" title="存储引擎是什么"></a>存储引擎是什么</h2><p>存储引擎听起来非常高大上, 其实干的事情真的很简单. 我写的第一个破百行的程序叫做 JPickle, J 是我英文名 Jim 的首字母, Pickle 代表着 Python 内置的序列化库 pickle. 它干了什么呢? 它可以实时序列化一个类 dict 的对象.</p><p>比如,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = JPickle(<span class="string">"/tmp/my_engine"</span>)</span><br><span class="line">a[<span class="string">'name'</span>] = <span class="string">'jim'</span></span><br></pre></td></tr></table></figure><p><code>name = jim</code> 这个信息就被存储到了 <code>/tmp/my_engine</code> 这个文件里, 下次只要再用 JPickle 打开同一个文件, 就可以读出 <code>name</code> 的值是 <code>jim</code>.</p><p>存储引擎是不是很简单? 做的事情在我看来就两件,</p><ul><li><p>维持一个映射关系, 比如 Key -&gt; Value, Key -&gt; Document</p></li><li><p>序列化并持久化映射</p></li></ul><p>Python 内置的 shelve 库也可以叫做一个存储引擎, 只是实现比较 naive. 现在想来当时的我也很 naive, 用着 Windows + Wing Python IDE + 微软雅黑. 槽点在于微软雅黑, 那时我觉得这世界上最好的编程字体就是它了吧. 直到很久之后我才发现等宽字体是多么的重要...</p><h2 id="存储引擎的实现"><a href="#存储引擎的实现" class="headerlink" title="存储引擎的实现"></a>存储引擎的实现</h2><h3 id="Python-shelve-库"><a href="#Python-shelve-库" class="headerlink" title="Python shelve 库"></a>Python shelve 库</h3><p>shelve 是没有硬盘索引概念的, 一切的映射都维护在一个字典里.</p><p>比如,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shelve</span><br><span class="line"></span><br><span class="line">d = shelve.open(filename) <span class="comment"># open -- file may get suffix added by low-level</span></span><br><span class="line">                          <span class="comment"># library</span></span><br><span class="line"></span><br><span class="line">d[key] = data   <span class="comment"># store data at key (overwrites old data if</span></span><br><span class="line">                <span class="comment"># using an existing key)</span></span><br><span class="line">data = d[key]   <span class="comment"># retrieve a COPY of data at key (raise KeyError if no</span></span><br><span class="line">                <span class="comment"># such key)</span></span><br><span class="line"><span class="keyword">del</span> d[key]      <span class="comment"># delete data stored at key (raises KeyError</span></span><br><span class="line">                <span class="comment"># if no such key)</span></span><br></pre></td></tr></table></figure><p><code>d[key] = data</code>, 实质上是把 data append 到某个文件, 然后把 data 在那个文件上 offset 以 <code>index[key] = data_offset</code> 的形式存在内存字典里.</p><p><code>data = d[key]</code> 的流程是从 index 读出 offset, 然后用 pickle.load 在文件的特定位置反序列化出 value 返回.</p><p>这种做法时兴叫做 <code>BitCask</code>, 即 key 和 offset 放内存, 再通过 offset 读硬盘得到 value. 说实话我不是很明白为什么这么简单的设计的冠名权给了 <code>BitCask</code>.</p><h2 id="JPickle"><a href="#JPickle" class="headerlink" title="JPickle"></a>JPickle</h2><p>这是我实现的库, 代码已经遗失了, 还挺可惜的. shelve 有两个重大的问题,</p><ul><li>shelve 没有断电保护</li></ul><p>当 <code>d[key] = data</code> 之后, 程序崩溃或者电脑断电了, shelve 的数据就丢了, 除非每次变更完都来一遍 <code>d.sync()</code>, 把 key -&gt; offset 的索引固化在硬盘上(value 已经是实时 append 的了). 所谓固化就是把整个索引重新 pickle.dump 一遍... 想象一下, 为了写 1KB 的数据, 就要重写 1MB 索引的可怕...</p><ul><li>shelve 没有垃圾回收</li></ul><p><code>del d[key]</code> 对于 shelve 来说是根本不回收硬盘空间的, 随着使用时间的增长, 空间占用快速单调递增.</p><p>我当时想得太多, 学得太少, 琢磨出了两个主意,</p><ul><li><p>每做一个变更, 我就把这个变更写进一个日志里, 然后即使断电了, 也可以通过回放日志来保持数据的安全性</p></li><li><p>建立一个垃圾回收的机制. 一旦有数据被删了, 就把被删掉的那个段标记为 dirty. 如果之后有数据刚好可以写进这个段, 就可以复用空间. 碎片化严重的话, 再进行完全重写.</p></li></ul><p>我实现完之后简直震惊了! Amazing! 我怎么这么厉害??? 我才初学编程就写出这么一个性能, 功能吊打标准库的程序, 我岂不是天才? 后来才发现想法一叫做 WAL(write ahead log), 想法二叫做 Compaction. 二者的年龄可能比我父母还大.</p><p>轮胎是圆的, 那是因为只能是圆的. 虽然流言终结者真的做过正方形轮胎... JPickle 已经具有了存储引擎的雏形了,</p><ul><li><p>一般的存储引擎都需要有一个 WAL / redo log 来确保操作的原子性和持久性</p></li><li><p>如果输入不是定长和定量的数据(99.9% 的情况), 存储空间的碎片化是不可避免的. 合格的存储引擎应该尽量回收碎片空间.</p></li></ul><h2 id="存储引擎索引"><a href="#存储引擎索引" class="headerlink" title="存储引擎索引"></a>存储引擎索引</h2><p>shelve, JPickle, BitCask 都选择了比较简单的索引实现, 索引整个都放在内存里. 但面对海量数据的时候, 很有可能索引是放不进内存里的, 所以必须要在硬盘上直接建立索引. 硬盘索引有两大家族.</p><h3 id="B-Tree-家族"><a href="#B-Tree-家族" class="headerlink" title="B-Tree 家族"></a>B-Tree 家族</h3><p>B-Tree 以及其变种如 B+-Tree 的算法流程可以自行了解. 其合理性在于硬盘, 无论是 HDD 还是 SSD 都是块设备, 一次读取最少读一块. HDD 一般是 512bytes, 称之为一个扇区(sector). SSD 则比较多样, 一般最少 4KB 称之为 page. 此外 HDD 还有很高的寻道时间, 一般在 10ms 左右.</p><p>因此对于硬盘来说, 读 8bytes 与读 4KB 是没有什么差别的. 将传统的红黑树 / AVL 树的小节点拍扁合并成接近硬盘块大小甚至更大的块的树就是 B-Tree. 千万级别的元素数量, 对于 B-Tree 来说, 只要跳转大约 4 次左右就够了. 换作二叉平衡树则要 20+ 次.</p><p>B-Tree 的最大深度为<br>\[ O(log_k n) \]</p><p>k 为单个 B-Tree 节点的 key 最大数量 / 2, 越大的 B-Tree 节点的 k 越大, 单节点读取时间越长, 但查询和修改需要跳转的次数越少. InnoDB 节点默认大小为 64KB.</p><p>B-Tree 索引也存在着相应的问题,</p><ul><li>写延迟与难以进行 Batch 优化</li></ul><p>假设要插入 key a, 在千万级别的 B-Tree 中大概率需要读 4 次节点, 以找到最接近 a 的已知 key. 一次写入操作 = 一次读取操作 + 可能的节点分裂 + 节点插入. 写速度恒 &lt;= 读速度. 这对于写多读少的场景, 比如 Google 的爬虫索引更新是不可接受的. 一个页面更新了, 搜索引擎并不需要立刻反应到搜索结果上, 更理想的是变更操作能攒起来, 然后大批量处理.</p><ul><li>写放大与 SSD 的随机写 GC</li></ul><p>B-Tree 节点内部一般是数组 + 二分查找实现的, 对节点的修改会导致整个节点重写, 这就有写放大. 情况在 SSD 时代更加严重, SSD 没有覆写操作. 只能先擦除一整个 block(一般包含 16 个 page), 然后再回写. 为了优化覆写的性能, SSD 有可能直接将数据写入一个新的空白块, 之前的块标记为脏, 等待后续的 GC. 当随机写越来越多时, GC 跟不上就会造成性能骤降. 我自己测试出来的结果是顺序写的吞吐可以到 2GB/s, 随机写在 GC 严重时只有 400MB/s.</p><ul><li>难以实现快照机制</li></ul><p>B-Tree 并不是一个 append-only 的数据结构, 只能用 COW(copy on write) 的方式实现快照, 这成本很高.</p><ul><li>空间利用率低</li></ul><p>传统 B-Tree 只能保证至少 1/2 的空间是被利用的.</p><h3 id="LSMT-家族"><a href="#LSMT-家族" class="headerlink" title="LSMT 家族"></a>LSMT 家族</h3><p>LSMT 是 Log-Structured Merge Tree 的缩写, 代表是由 Google 传奇程序员 Jeff Dean 实现的 LevelDB. LevelDB 是 Google GFS / BigTable 的基石. 相比于 197X 年就提出的 B-Tree, LSMT 大约在 2000 年才有了第一个可靠的实现(LevelDB).</p><p>究其原因, 我认为是 LSMT 在理论上先天是不美的, 这是一个工程师才会喜欢的数据结构. 简单概括下逻辑就是放弃数据的全局有序性, 只确保在某一块内的数据有序, 通过限制 key 区间重叠的块的数量来保证读取速度. 细节可以 wiki. 在最差情况下(输入的 key 都和现有块的区间重叠造成雪崩式 Compaction), LSMT 表现糟糕得一塌糊涂. 除此之外, LSMT 剩下的就都是优点了.</p><ul><li>逻辑简单, 分层清楚, 易于优化</li></ul><p>MemTable, IMMemTable, SSTable 可以看成三个独立的组件. Compaction 只需要处理 IMMemTable 和 SSTable 这种 immutable 的数据结构. 这个就好像 Raft v.s. Multi-Paxos. Raft 看似限制多, 但因为它实现简单, 工程师反而有更多的信心去优化.</p><ul><li>空间利用率高</li></ul><p>LSMT 会频繁 Compaction, 这样被删除的 key 占用的空间就得到了释放. 同时 SSTable 可以用更激进的块压缩(e.g. zstd)进一步节约空间.</p><ul><li>数据冷热分层, cache 利用率高</li></ul><p>数据天然存在时间和空间连续性. 热 key 一般在上层, cache 不容易 miss. 那么对于热 key 来说, 读很大概率都是 O(1) 的.</p><ul><li><p>无随机写, append-only</p></li><li><p>通过保证局部有序实现写操作无阻塞</p></li></ul><p>这个是 LSMT 的精髓. 对于全局有序的数据结构, 读和写是需要立刻完成的. LSMT 外加了一个 Compaction 操作, 使得写不再依赖读了, 达成无阻塞. Compaction 成了一个平衡读写性能的中间操作. 根据场景不同, LSMT 可以用不同的 Compaction 参数. 比如, 读很重要, 那么就可以提升 Compaction 的频率.</p><h2 id="读写引擎的未来"><a href="#读写引擎的未来" class="headerlink" title="读写引擎的未来"></a>读写引擎的未来</h2><p>由于有 RocksDB 这个优秀的开源 LSMT KV 存储引擎实现, 使用 RocksDB 基本上已经是开源社区的主流选择了, 比如 TiKV, CockroachDB, Pika. 但是不是 RocksDB 就没别的读写引擎能挑战了呢?</p><p>我觉得不是的. 一些 LSMT 很科学的假设在飞速发展的存储技术面前已经有些失效了.</p><ul><li><p>随机读比顺序读慢很多 ❎ Intel P4510 4 KB 随机吞吐 2.5 GB/s, 64 MB 顺序吞吐 2.9 GB/s</p></li><li><p>持久化 IO 设备不是 Byte-Addressable 的 ❎ NVM 与内存没有差别, 支持 load 与 store 操作</p></li></ul><p>新思路</p><ul><li><p>Wisckey, key 存储在 LSMT 中, value 存储在 value log 里, 充分利用 SSD 强悍的随机读取能力</p></li><li><p>BzTree, 直接在 NVM 上用 CAS 操作进行存储</p></li></ul><p>除了存储设备上的快速发展, RocksDB 本身的结构在云时代也存在许多局限.</p><ul><li><p>多租户 / QOS</p></li><li><p>多实例同步</p></li><li><p>多线程阻塞 IO 模型</p></li></ul><p>尤其是多线程阻塞 IO 模型, 这一定会导致 RocksDB 整个重写. 我自己测试 P4510, 阻塞 IO 需要 128 个线程才比得上 libaio 的 8 个线程, 而 Linux Kernel 5.1 又加入了 <strong>io_uring</strong>, 性能相对于 libaio 又大幅度提升. 或许等 Ubuntu / Debian 有 5.1 内核的 LTS 发行版的时候, 我就可以去创业了? 专做高性能 KV 存储🤔.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我这个周末都在被高等数学支配的恐惧中度过, (ノへ￣、) 写一篇我擅长方面的博文放松下, 希望能保持每周一更的频率. 什么 InnoDB, WiredTiger, LevelDB, RocksDB, 相关的文章有很多, 但为什么这些设计有道理呢? 我没有发现一篇讲得很明白.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>雾计算第一期: 高中知识回顾</title>
    <link href="/2019/05/03/%E9%9B%BE%E8%AE%A1%E7%AE%97%E7%AC%AC%E4%B8%80%E6%9C%9F-%E9%AB%98%E4%B8%AD%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/"/>
    <id>/2019/05/03/雾计算第一期-高中知识回顾/</id>
    <published>2019-05-02T16:11:53.000Z</published>
    <updated>2019-07-21T11:09:07.242Z</updated>
    
    <content type="html"><![CDATA[<p>雾计算是一个梗, 来自 RocksDB 核心开发者, siying. 在 &quot;大学生适合学云计算吗?&quot; 问题下, 他的回答是 &quot;都2019年了，还搞什么云计算啊。雾计算都快过时了。好好看看雨计算之类的。&quot; 云计算代表着传统 CS 工业界, 那 CS 的另一个大热门, AI / ML, 我就称之为雾计算了. 雨计算留给区块链吧. 由于雾计算的前置知识是数学, 本文先把高中的数学捋了一遍.</p><a id="more"></a><h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><p>全体奇数可表示为</p><p>\[ E = \{ x \in \mathbf{Z} | x = 2k + 1, x \in \mathbf{Z} \} \]</p><p>若 B 集合包含 A 集合的所有元素, 则 A 是 B 的子集.</p><p>若 B 集合内的所有元素与 A 集合内的所有元素相同, 则 A 与 B 相等.</p><p>若 A 是 B 的子集且 A 与 B 不相等, 则 A 是 B 的真子集.</p><p>集合间的操作, 交(or), 并(and), 补(complement). 例, 在自然数范围内, 奇数集的补集是偶数.</p><p>个人补充: 集合内的元素个数称之为基数(cardinal number). 如果两个集合内的元素可以一对一映射, 那么这两个集合等势. 例, 自然数集与偶数集等势, 所以自然数与偶数一样多. 有点反直觉? well, 我觉得这更像是一个语文问题, 取决于如何看待无穷集合以及什么叫 &quot;一样多&quot;. 数学上, 自然数集与偶数集就是等势的.</p><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>函数是一种映射的逻辑. 设 x 为输入, y 为输出, 将 x 变换为 y 的逻辑可以抽象为一个函数. x 的取值范围称之为定义域, y 的取值范围称之为值域.</p><p>增函数 / 减函数 / 单调递增 / 单调递减 / 极值, 略.</p><p>偶函数(even function), even 在英文中不仅指偶数, 还有对称之意. even function 即对称的函数. 将偶函数置于坐标系中, 形成的图像关于 y 轴对称. 代数表达: f(-x) = f(x).</p><p>奇函数(odd function), odd 在英文中可用于形容事物奇特.奇函数的性质非常奇特. f(-x) 可以将 -x 的负号 &quot;抽离&quot; 得到 f(-x) = -f(x).</p><h3 id="指数函数"><a href="#指数函数" class="headerlink" title="指数函数"></a>指数函数</h3><p>指数函数性质</p><p>\[ a^m a^n = a^{m+n} \]</p><p>\[ (a^m)^n = a^{mn} \]</p><p>\[ (ab)^r = a^r b^r \]</p><p>定义分数指数和负指数为</p><p>\[ a^{\frac{m}{n}} = \sqrt[n]{a^m} \]</p><p>\[ a^{-\frac{m}{n}} = \frac{1}{a^{\frac{m}{n}}} \]</p><p>个人补充: 困扰我很久的一个问题是为什么这么<strong>定义</strong>? 难道数学大厦是建立在死记硬背上吗? 我喜欢从直觉上理解问题, 但分数指数和负指数, 完全没有现实参照物.</p><p>但原因其实真的很简单! 数学不需要和现实对应. 我们能用数学来解释物理世界的问题, 那只是恰好物理学家能从数学的世界里拿到趁手的工具罢了. 这是不是意味着可以随意定义呢? 不是的, 引入一个数学定义起码要满足两个条件.</p><ol><li><p>尽量跟现有的规则不冲突</p></li><li><p>有用</p></li></ol><p>显然, 分数指数 / 负指数是和现有规则不冲突的. 因为我们是用了现有规则才定义了二者. 以负指数为例, 有用性体现在哪里? 1 + 1 = 2, 一个实数加一个实数得到了另一个实数. 我可以对任意两个实数做加法操作, 必然得到另一个实数. (延伸: 这个应该叫做实数上的加法群) 那么 \( a^m \div a^n = ?, n&gt;m \), 结果应该是 \( a^{m-n} \). m-n 显然是个负数. 如果规定负指数无意义, 但这个式子显然是有意义的. 为了解决这个冲突, 才有了负指数的引入. 分数指数同理.</p><h3 id="对数函数"><a href="#对数函数" class="headerlink" title="对数函数"></a>对数函数</h3><p>对数函数性质</p><p>\[ \log_a^{MN} = \log_a^M + log_a^N \]</p><p>\[ \log_a^{\frac{M}{N}} = \log_a^M - \log_a^N \]</p><p>\[ \log_a^{M^n} = n \log_n^M \]</p><p>换底公式</p><p>\[ \log_a^b = \frac{\log_c^b}{\log_c^a} \]</p><p>个人补充: 如何用对数表加快乘法运算? 对数表记录了 x &lt; --- &gt; lg x 的映射. 比如要计算 M * N, 先去对数表去找 lg M 与 lg N, 求和得 lg MN. 再反查 log MN 对应的 MN 是多少. 乘法运算就化为了加法运算.</p><h3 id="幂函数"><a href="#幂函数" class="headerlink" title="幂函数"></a>幂函数</h3><p>略</p><h3 id="空间几何基础"><a href="#空间几何基础" class="headerlink" title="空间几何基础"></a>空间几何基础</h3><p>略</p><h3 id="解析几何基础"><a href="#解析几何基础" class="headerlink" title="解析几何基础"></a>解析几何基础</h3><p>解析几何一言以蔽之就是用坐标系内的代数式来表达几何关系. 代数式的抽象程度更高, 更易于计算. 代数系统变换更容易, 在几何系统中则要用辅助线 / 平移之类的技巧.</p><p>直线的方程 / 两点距离公式 / 点线距离公式, 自行搜索. 我懒得打 LaTex 了 -。-</p><h3 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h3><p>略</p><h3 id="三角函数"><a href="#三角函数" class="headerlink" title="三角函数"></a>三角函数</h3><h4 id="弧度制"><a href="#弧度制" class="headerlink" title="弧度制"></a>弧度制</h4><p>角度制存在一个问题就是它和实数体系是不完美兼容的. 180° * 2 = 360 °. 这可以理解, 那请问 180° + 2 等于什么? 180° 的平方又是什么? 这就存在着特例. 任何理论都应该遵循奥卡姆剃刀原则, 选择解释力最强最简单的模型.</p><p>角度是用圆等分成 360 份定义的, 弧度也使用圆定义的. 半径为 1 的圆称之为单位圆. 180° 所对应的圆是半圆, <strong>弧长</strong>等于 π. 所以 1π 的弧度对应 180°. 这样特例就被归纳到一个更通用的体系里了. 180° 是一个特殊的存在, 但 1π 弧度只是一个普通的比例关系.</p><h4 id="任意角的三角函数"><a href="#任意角的三角函数" class="headerlink" title="任意角的三角函数"></a>任意角的三角函数</h4><p>初中数学告诉我们, sin 是对边比斜边, cos 是邻边比斜边, tan 是对边比邻边, 通过画图, 比如等腰直角三角形, 可以得出 tan(45°) = 1, 还可通过各种变化求一些有限的三角函数值.</p><p>悬而未解的问题是 sin(100°) 是什么? 显然我们没有办法画出一个含有 100° 角的直角三角形. 在引入了弧度制后, 又有 sin(-0.9π) 是什么? 同样的, 没有定义, 那就合理地扩充定义.</p><p><img src="/img/Trig_functions_on_unit_circle_zh.png" alt="Trig_functions_on_unit_circle"></p><p>延伸: 定义了任意角的三角函数后, 计算三角函数仍然不是一个简单的工作. 因为我们没有办法用一个很简单的公式表明三角函数究竟等于很什么. 我们只知道有这么一个逻辑完成了一个实数到实数的特定变换. 这也是抽象的威力所在. 三角函数在计算机是使用泰勒公式展开近似的.</p><h4 id="三角函数的公式与性质"><a href="#三角函数的公式与性质" class="headerlink" title="三角函数的公式与性质"></a>三角函数的公式与性质</h4><p>自行了解振幅 / 周期 / 频率 / 相位 / 初相, 等.</p><p>个人补充: sin 与 cos 是周期函数, 在物理上被用来描述 &quot;简谐运动&quot;, 比如钟摆. 为什么数学可以用来描述这么多物理现象呢? 我个人的看法是现实世界是连续的且具有某种程度上的对称性. 数学家做的很多事情就是推广, e.g. 从离散的推广到连续的; 发现, e.g. 对数与指数的互逆关系. 这些都是和现实世界不谋而合的.</p><h3 id="平面向量"><a href="#平面向量" class="headerlink" title="平面向量"></a>平面向量</h3><p>略</p><h3 id="解三角形"><a href="#解三角形" class="headerlink" title="解三角形"></a>解三角形</h3><p>自行了解正弦定理 / 余弦定理.</p><h3 id="数列"><a href="#数列" class="headerlink" title="数列"></a>数列</h3><p>略</p><h3 id="不等式"><a href="#不等式" class="headerlink" title="不等式"></a>不等式</h3><p>略</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>说是回顾, 但是略了好多🙈. 一是精力所限, 我毕竟不是以写博文为生的. 二是高中时期的一些记忆性知识都可以被大学层次的数学统一. 如果有志雾计算, 数学三大件, 高等数学 / 线性代数 / 数理统计, 必然要啃下的, 学的时候自然会明白. 这里也没必要赘述了.</p><p>最后, 推荐两个数学方面的视频作者.</p><ol><li><p>3B1B 3Blue1Brown @ YouTube</p></li><li><p>张宇数学考研系列</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;雾计算是一个梗, 来自 RocksDB 核心开发者, siying. 在 &amp;quot;大学生适合学云计算吗?&amp;quot; 问题下, 他的回答是 &amp;quot;都2019年了，还搞什么云计算啊。雾计算都快过时了。好好看看雨计算之类的。&amp;quot; 云计算代表着传统 CS 工业界, 那 CS 的另一个大热门, AI / ML, 我就称之为雾计算了. 雨计算留给区块链吧. 由于雾计算的前置知识是数学, 本文先把高中的数学捋了一遍.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>FAST 2019 DistCache</title>
    <link href="/2019/04/15/FAST-2019-DistCache/"/>
    <id>/2019/04/15/FAST-2019-DistCache/</id>
    <published>2019-04-14T18:39:05.000Z</published>
    <updated>2019-07-21T11:08:53.083Z</updated>
    
    <content type="html"><![CDATA[<p>本周我读的最佳论文是 FAST 2019 DistCache. 缓存系统就和人生一样, 有时简单的小小变动就会产生巨大的意想不到的影响. /(ㄒoㄒ)/~~</p><a id="more"></a><h2 id="DistCache-背景知识"><a href="#DistCache-背景知识" class="headerlink" title="DistCache 背景知识"></a>DistCache 背景知识</h2><ul><li><p>Balls into bins 问题</p></li><li><p>The Power of Two Random Choices</p></li><li><p>LB 与 cache 的互补关系</p></li></ul><p>Balls into bins 问题讲的是如果有 M 个小球随机等概率地扔进 N 个垃圾桶, 那么装球最多的那个垃圾桶大概率会有多少个球?</p><p>我第一反应是正态分布吧. 毕竟看起来就是一连串互相独立的随机决定. 可能正态分布的 bound 还不够 tight. 出于精力的原因, 我并没有去看数学推导过程. 这里直接列出结果.</p><p>\[ O ( \log n / \log \log n ) \]</p><p>上面那个公式计算的是 max load. 假设有 64 个 node, LB 随机分配流量, 那么 load 最大的 node, 负载将会是平均负载的 log 32 / log log 32 = 2.7 倍. 那为了保证 SLA, 每个节点都必须预留出 70 % 的资源空闲以应对单纯因为负载不均造成的 burst. 我已经忽略掉所有常数项了, 结果真是太糟了...</p><p>当然现实可能没这么悲观. 一些负载过高的节点可以暂时从 LB 里摘掉. 看起来解决了一个问题, 但又有了一个新问题就是现在谁来管理 LB 的状态? 据说阿里搞云梯一, 上千台的 Hadoop 集群就经常受偏压困扰. 单点就打崩了.</p><p>解决方案出奇的简单(起码理论上是这样的), 这就引出了 The Power of Two Random Choices. LB 在分流的时候, 随机比较两台(d = 2)后端服务器的 load, 选最小, 得到新 bound.</p><p>\[ O ( \log \log n / \log d ) \]</p><p>log d 是常数, 可忽略.</p><p>\[ O ( \log \log n ) \]</p><p>log log 32 = 1.2, 那么只要预留 20% 的资源就够了(忽略常数项的情况下 :-D). 震惊!</p><p>最后一个是 LB 与 cache 的互补关系. 2 choices 可以解决无状态的 load balance 问题, 但这对存储不起作用. 因为 LB 没有办法按 load 分流, 比如 key A 存在服务器 S 上, S 跑满了, LB 就能把 query redirect 到别的机器上吗?</p><p>Small Cache, Big Effect 这篇 paper 很大程度上解决了这个问题. LB 与 cache layer 存在很强的互补关系. LB 讨厌 imbalance, 但 cache 喜欢. query 越 skew, cache 效率越高.</p><p>我们当然知道绝大绝大多数情况下 cache 越多, 系统性能越好(除非 network 是瓶颈), 那么在一个多 node 的存储系统, cache 至少要多少才有足够的信心说这个系统没有热点呢? paper 给出的答案吓死人了! 居然只要 O(n log n)! n 是 node 数量.</p><p>WTF? 居然与 key 的数量无关? 那假如有一亿个 key, 4 个节点, 岂不是只要 cache 6 组 key 就够? 这太反直觉了. 但看了推导居然觉得还是很容易理解的. 作者构造了一组恶意 query 来模拟最差的情况, 然后做了些高中程度的数学消元就好了.</p><p>有几点前提是这个证明巧妙的地方, 通过定义绕过了很多很难处理的问题.</p><ul><li><p>key 的分布必须均匀, 即使产生 skew 也只能是因为类似 Bins into balls 那种自然抖动产生的. 换言之, 如果一亿组 key, 然后九千万都在服务器 A, 起码 small cache 是救不了的... 也就是 hash function 必须得是 perfect 的.</p></li><li><p>cache 必须未卜先知, 知道哪些 key 是 hottest 的, 尽管实际生产上是绝对做不到的. cache 还必须拥有无限 capacity, 多少 query 都能吸收, 这个倒是还好, cache 一般就是快得飞起.</p></li></ul><p>因为 key 大体分布均匀, hottest objects 必然在 cache 里, O(n log n) 实际上是限制了单个 key 的被 query 次数上限来抵消 Bins into balls 中描述的自然抖动. 所以最终可以做到无论 query 什么分布, key 有多少, O(n log n) 组 cache 就够了.</p><h2 id="DistCache"><a href="#DistCache" class="headerlink" title="DistCache"></a>DistCache</h2><p>千呼万唤始出来, 终于说到了 DistCache. 其实这部分跟 Small Cache 那篇差不多, 不复杂, 但突出一个巧. DistCache 的作者团队(Xin Jin)之前在折腾一个刷分项目(玩笑, 纯属推测). 根据理论, 只要单点够强, 很小的 cache 就可以刷很高的分. 那 cache 足够小是不是可以直接放进专有硬件使用专有协议了? 于是他们就把 LB 和 cache 一起打包进了 switch 里... 当然刷了很高的分.</p><p>插个话, 这个体现了无序 KV 是一个很好的&quot;设计&quot;或者说&quot;品位&quot;. 上层开发者好理解, 下层开发者好刷分. 天然可拆分, 可并发. 与此相同的应该就是&quot;流&quot;这个概念了. 一个比较糟糕的例子就是 JS 的隐式 type cast. 上层开发者搞不懂, 下层开发者也不好去掉 if 来加速.</p><p>言归正传, 刷分是无止境的. 即使用了专有硬件, 专有协议, 把交换机, LB, Cache 合并了, 还是有单点. 正所谓, 单点就刷不了分. KV 是可拆分的. 那很自然的想法是多来几个 cache server 就好了啊.</p><p>新问题来了, 怎么确保 cache server 是 balance 的呢? cache server 已经是刷分最快的了, 没设备给 cache server 做防止 imbalance 的 cache 了...</p><p>作者给出的方案很简单, 就是双层 cache. 当前所有 cache server 的所有 KV 用一个新的 hash function 存在另一层 cache layer 里. 从数学和直觉上可以确保, 任意一层的 cache server 出现了热点, 那么这个热点的 KV 数据在另一个 cache layer 是分散的, 无热点的.</p><p>然后在哪一层 cache 找 key 的问题又可以转化为 The Power of Two Random Choices 问题, 选负载最低的. 好了, 让我们继续刷分吧!</p><h2 id="体会"><a href="#体会" class="headerlink" title="体会"></a>体会</h2><p>数据存储冷热分离, 大有搞头! cache 远比我想象中的高效. 热数据存储就相当于冷数据的 cache + LB 了. 冷数据打散进大规模 HDD 集群. 热存储集群保证冷存集群不会出现热点, 那么冷存集群就可以维持一个比较高的 throughput. 整体就会很快, 不是吗?</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周我读的最佳论文是 FAST 2019 DistCache. 缓存系统就和人生一样, 有时简单的小小变动就会产生巨大的意想不到的影响. /(ㄒoㄒ)/~~&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Cuckoo Hashing</title>
    <link href="/2019/04/07/Cuckoo-Hashing/"/>
    <id>/2019/04/07/Cuckoo-Hashing/</id>
    <published>2019-04-07T06:43:43.000Z</published>
    <updated>2019-07-21T11:08:58.033Z</updated>
    
    <content type="html"><![CDATA[<p>Hash Table 可能是最简单也性能最高的数据结构了. 但它有个问题叫做 Hash Collision(哈希碰撞). JVM 和 C++ STL 的做法是链表 Bucket, 还有个流派是 Open Addressing(开链). Cuckoo Hashing 是一种特殊的开链.</p><a id="more"></a><h2 id="链表-Bucket"><a href="#链表-Bucket" class="headerlink" title="链表 Bucket"></a>链表 Bucket</h2><p>链表 Bucket 最简单的实现就是纯单向链表, 如果 A 与 B 都 hash 到了 K, 在 K 上建立一个单链表串联 A 与 B. 由于链表的性能在元素数量少的情况下远逊 array, array 在数量多的情况下又远逊平衡树. 比较高端的实现(e.g. JVM)在 bucket size 小的时候使用 array, 数量到达一定阈值, 再全部整理成一颗平衡树.</p><p>但这种做法破坏了程序的两大美德(我定的).</p><ul><li><p>少用指针</p></li><li><p>少动态内存分配</p></li></ul><p>前者会导致 cache miss, 后者是相当昂贵的操作.</p><h2 id="开链"><a href="#开链" class="headerlink" title="开链"></a>开链</h2><p>A hash 到了 K, 这时 B 也 hash 到了 K, B 必须尝试新位置, 直到找到一个可用位置. 最简单的方法是 Linear Probing. K 被占了就去找 K+1, K+2... 这样有可能会导致部分的区块使用率很高, 所以一般来说用第二个或更多 hash function 来算出新位置会好点.</p><p>多次 hash 可以更好地消除原有 key 分布的特征, 使得 key 可以均匀分布在 table 上. 因为 p 为碰撞概率, t 为 hash 次数, 多次 hash 的碰撞概率就是 p^t 了.</p><p>但真正的问题在于, <strong>要怎么 look up 呢?</strong> 如果用了 10 次 hash 才将一个元素放进 table, 那么读取在最差的情况下需要 10 次 look up 才能确保元素不在这个集合内. 再多跳几次, 可能还不如直接上 O(log n) 的平衡树了呢.</p><h2 id="Cuckoo-Hashing"><a href="#Cuckoo-Hashing" class="headerlink" title="Cuckoo Hashing"></a>Cuckoo Hashing</h2><p>Cuckoo Hashing 最精妙也是唯一的改动是 kick out, <strong>将多次 hash 的 look up 压力分散到了多个 key 而非单一 key 上.</strong> A hash 到了 K, B 也 hash 到了 K, 发现已经被 A 占用了, 尝试用第二种 hash function, 将 B hash 到了 M, 发现 M 也已经被占用了. 这时可以任意将 K 或者 M 上的元素踢出来, 然后将 B 置入. 被踢出来的元素要继续尝试以上流程进行插入. 每个 key 最多存在于两个位置, 所以 look up 最多跳两次.</p><p>这种不断踢出元素的过程, 会构成一幅图叫做 Cuckoo Graph, 只有很低概率会产生死循环. 原论文给出的结论是 2 个 hash function 在 load factor 在 50% 的情况下是可靠的, 如果是用 3 个 hash function, load factor 可以进一步提升至 91%.</p><h2 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h2><p>工程实现上, 不大可能无限制 kick out. 我测试了下不同 kick 次数的表现.</p><p>代码和输出较长, 先把结果写在这边.</p><ul><li><p>预设 load factor 为 83% 时, 97% 的元素插入成功(3 hash functions + 7 max kicks)</p></li><li><p>预设 load factor 为 100% 时, 91% 的元素插入成功(3 hash functions + 8 max kicks)</p></li></ul><p>Cuckoo Hashing + 任意插入失败情况下的 backup store 就是一个非常内存节约型的 Hash Table 了!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randrange</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5, sha1,sha3_256</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleHashTable</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._table = [<span class="string">''</span>] * <span class="number">6000</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, k: str)</span> -&gt; bool:</span></span><br><span class="line">        pos = hash(k) % <span class="number">6000</span></span><br><span class="line">        <span class="keyword">if</span> self._table[pos]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self._table[pos] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'SimpleHashTable'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayersCuckooTable</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_kick=<span class="number">1</span>)</span>:</span></span><br><span class="line">        self._tables = [[<span class="string">''</span>] * <span class="number">3000</span>, [<span class="string">''</span>] * <span class="number">3000</span>]</span><br><span class="line">        self._max_kick = max_kick</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, k: str, nth_kick=<span class="number">0</span>)</span> -&gt; bool:</span></span><br><span class="line">        pos_0 = hash((k, <span class="number">0</span>)) % <span class="number">3000</span></span><br><span class="line">        pos_1 = hash((k, <span class="number">1</span>)) % <span class="number">3000</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">0</span>][pos_0]:</span><br><span class="line">            self._tables[<span class="number">0</span>][pos_0] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">1</span>][pos_1]:</span><br><span class="line">            self._tables[<span class="number">1</span>][pos_1] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> nth_kick &lt; self._max_kick:</span><br><span class="line">            <span class="keyword">if</span> randrange(<span class="number">0</span>, <span class="number">2</span>):</span><br><span class="line">                k, self._tables[<span class="number">0</span>][pos_0] = self._tables[<span class="number">0</span>][pos_0], k</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                k, self._tables[<span class="number">1</span>][pos_1] = self._tables[<span class="number">1</span>][pos_1], k</span><br><span class="line">            <span class="keyword">return</span> self.insert(k, nth_kick + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'2 layers + %d kicks'</span> % self._max_kick</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreeLayersCuckooTable</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_kick=<span class="number">1</span>)</span>:</span></span><br><span class="line">        self._tables = [[<span class="string">''</span>] * <span class="number">2000</span>, [<span class="string">''</span>] * <span class="number">2000</span>, [<span class="string">''</span>] * <span class="number">2000</span>]</span><br><span class="line">        self._max_kick = max_kick</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, k: str, nth_kick=<span class="number">0</span>)</span> -&gt; bool:</span></span><br><span class="line">        pos_0 = hash((k, <span class="number">0</span>)) % <span class="number">2000</span></span><br><span class="line">        pos_1 = hash((k, <span class="number">1</span>)) % <span class="number">2000</span></span><br><span class="line">        pos_2 = hash((k, <span class="number">2</span>)) % <span class="number">2000</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">0</span>][pos_0]:</span><br><span class="line">            self._tables[<span class="number">0</span>][pos_0] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">1</span>][pos_1]:</span><br><span class="line">            self._tables[<span class="number">1</span>][pos_1] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">2</span>][pos_2]:</span><br><span class="line">            self._tables[<span class="number">2</span>][pos_2] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> nth_kick &lt; self._max_kick:</span><br><span class="line">            sol = randrange(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">            <span class="keyword">if</span> sol == <span class="number">0</span>:</span><br><span class="line">                k, self._tables[<span class="number">0</span>][pos_0] = self._tables[<span class="number">0</span>][pos_0], k</span><br><span class="line">            <span class="keyword">elif</span> sol == <span class="number">1</span>:</span><br><span class="line">                k, self._tables[<span class="number">1</span>][pos_1] = self._tables[<span class="number">1</span>][pos_1], k</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                k, self._tables[<span class="number">2</span>][pos_2] = self._tables[<span class="number">2</span>][pos_2], k</span><br><span class="line">            <span class="keyword">return</span> self.insert(k, nth_kick + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'3 layers + %d kicks'</span> % self._max_kick</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreeVLayersCuckooTable</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_kick=<span class="number">1</span>)</span>:</span></span><br><span class="line">        self._table = [<span class="string">''</span>] * <span class="number">6000</span></span><br><span class="line">        self._tables = [self._table] * <span class="number">3</span></span><br><span class="line">        self._max_kick = max_kick</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert</span><span class="params">(self, k: str, nth_kick=<span class="number">0</span>)</span> -&gt; bool:</span></span><br><span class="line">        pos_0 = hash(sha3_256(k.encode(<span class="string">'ascii'</span>)).hexdigest()) % <span class="number">6000</span></span><br><span class="line">        pos_1 = hash(md5(k.encode(<span class="string">'ascii'</span>)).hexdigest()) % <span class="number">6000</span></span><br><span class="line">        pos_2 = hash(sha1(k.encode(<span class="string">'ascii'</span>)).hexdigest()) % <span class="number">6000</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">0</span>][pos_0]:</span><br><span class="line">            self._tables[<span class="number">0</span>][pos_0] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">1</span>][pos_1]:</span><br><span class="line">            self._tables[<span class="number">1</span>][pos_1] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self._tables[<span class="number">2</span>][pos_2]:</span><br><span class="line">            self._tables[<span class="number">2</span>][pos_2] = k</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> nth_kick &lt; self._max_kick:</span><br><span class="line">            sol = randrange(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">            <span class="keyword">if</span> sol == <span class="number">0</span>:</span><br><span class="line">                k, self._tables[<span class="number">0</span>][pos_0] = self._tables[<span class="number">0</span>][pos_0], k</span><br><span class="line">            <span class="keyword">elif</span> sol == <span class="number">1</span>:</span><br><span class="line">                k, self._tables[<span class="number">1</span>][pos_1] = self._tables[<span class="number">1</span>][pos_1], k</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                k, self._tables[<span class="number">2</span>][pos_2] = self._tables[<span class="number">2</span>][pos_2], k</span><br><span class="line">            <span class="keyword">return</span> self.insert(k, nth_kick + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'3 virtual layers + %d kicks'</span> % self._max_kick</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">        tables = [[SimpleHashTable(), <span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">            tables.append([TwoLayersCuckooTable(i), <span class="number">0</span>])</span><br><span class="line">            tables.append([ThreeLayersCuckooTable(i), <span class="number">0</span>])</span><br><span class="line">            tables.append([ThreeVLayersCuckooTable(i), <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6000</span>):</span><br><span class="line">            k = str(i)</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> tables:</span><br><span class="line">                r = t[<span class="number">0</span>].insert(k)</span><br><span class="line">                <span class="keyword">if</span> r:</span><br><span class="line">                    t[<span class="number">1</span>] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                j = i + <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> j % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">                    print(str(t[<span class="number">0</span>]), <span class="string">": %d / %d = %d%%"</span> % (t[<span class="number">1</span>], j, t[<span class="number">1</span>] * <span class="number">100</span> // j))</span><br><span class="line">                    <span class="keyword">if</span> t <span class="keyword">is</span> tables[<span class="number">-1</span>]:</span><br><span class="line">                        print(<span class="string">'---\n'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    run()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br></pre></td><td class="code"><pre><span class="line">SimpleHashTable : 474 / 500 = 94%</span><br><span class="line">2 layers + 1 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 1 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 1 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 2 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 2 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 2 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 3 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 3 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 3 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 4 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 4 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 4 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 5 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 5 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 5 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 6 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 6 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 6 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 7 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 7 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 7 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 8 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 8 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 8 kicks : 500 / 500 = 100%</span><br><span class="line">2 layers + 9 kicks : 497 / 500 = 99%</span><br><span class="line">3 layers + 9 kicks : 500 / 500 = 100%</span><br><span class="line">3 virtual layers + 9 kicks : 500 / 500 = 100%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 906 / 1000 = 90%</span><br><span class="line">2 layers + 1 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 1 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 1 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 2 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 2 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 2 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 3 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 3 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 3 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 4 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 4 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 4 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 5 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 5 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 5 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 6 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 6 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 6 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 7 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 7 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 7 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 8 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 8 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 8 kicks : 1000 / 1000 = 100%</span><br><span class="line">2 layers + 9 kicks : 986 / 1000 = 98%</span><br><span class="line">3 layers + 9 kicks : 997 / 1000 = 99%</span><br><span class="line">3 virtual layers + 9 kicks : 1000 / 1000 = 100%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 1304 / 1500 = 86%</span><br><span class="line">2 layers + 1 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 1 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 1 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 2 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 2 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 2 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 3 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 3 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 3 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 4 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 4 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 4 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 5 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 5 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 5 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 6 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 6 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 6 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 7 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 7 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 7 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 8 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 8 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 8 kicks : 1500 / 1500 = 100%</span><br><span class="line">2 layers + 9 kicks : 1446 / 1500 = 96%</span><br><span class="line">3 layers + 9 kicks : 1479 / 1500 = 98%</span><br><span class="line">3 virtual layers + 9 kicks : 1500 / 1500 = 100%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 1681 / 2000 = 84%</span><br><span class="line">2 layers + 1 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 1 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 1 kicks : 1998 / 2000 = 99%</span><br><span class="line">2 layers + 2 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 2 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 2 kicks : 1998 / 2000 = 99%</span><br><span class="line">2 layers + 3 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 3 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 3 kicks : 1999 / 2000 = 99%</span><br><span class="line">2 layers + 4 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 4 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 4 kicks : 2000 / 2000 = 100%</span><br><span class="line">2 layers + 5 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 5 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 5 kicks : 2000 / 2000 = 100%</span><br><span class="line">2 layers + 6 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 6 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 6 kicks : 2000 / 2000 = 100%</span><br><span class="line">2 layers + 7 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 7 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 7 kicks : 2000 / 2000 = 100%</span><br><span class="line">2 layers + 8 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 8 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 8 kicks : 2000 / 2000 = 100%</span><br><span class="line">2 layers + 9 kicks : 1892 / 2000 = 94%</span><br><span class="line">3 layers + 9 kicks : 1956 / 2000 = 97%</span><br><span class="line">3 virtual layers + 9 kicks : 2000 / 2000 = 100%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 2025 / 2500 = 81%</span><br><span class="line">2 layers + 1 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 1 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 1 kicks : 2495 / 2500 = 99%</span><br><span class="line">2 layers + 2 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 2 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 2 kicks : 2497 / 2500 = 99%</span><br><span class="line">2 layers + 3 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 3 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 3 kicks : 2498 / 2500 = 99%</span><br><span class="line">2 layers + 4 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 4 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 4 kicks : 2500 / 2500 = 100%</span><br><span class="line">2 layers + 5 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 5 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 5 kicks : 2500 / 2500 = 100%</span><br><span class="line">2 layers + 6 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 6 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 6 kicks : 2500 / 2500 = 100%</span><br><span class="line">2 layers + 7 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 7 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 7 kicks : 2500 / 2500 = 100%</span><br><span class="line">2 layers + 8 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 8 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 8 kicks : 2500 / 2500 = 100%</span><br><span class="line">2 layers + 9 kicks : 2313 / 2500 = 92%</span><br><span class="line">3 layers + 9 kicks : 2401 / 2500 = 96%</span><br><span class="line">3 virtual layers + 9 kicks : 2500 / 2500 = 100%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 2349 / 3000 = 78%</span><br><span class="line">2 layers + 1 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 1 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 1 kicks : 2980 / 3000 = 99%</span><br><span class="line">2 layers + 2 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 2 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 2 kicks : 2986 / 3000 = 99%</span><br><span class="line">2 layers + 3 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 3 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 3 kicks : 2992 / 3000 = 99%</span><br><span class="line">2 layers + 4 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 4 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 4 kicks : 2996 / 3000 = 99%</span><br><span class="line">2 layers + 5 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 5 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 5 kicks : 2996 / 3000 = 99%</span><br><span class="line">2 layers + 6 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 6 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 6 kicks : 3000 / 3000 = 100%</span><br><span class="line">2 layers + 7 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 7 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 7 kicks : 2999 / 3000 = 99%</span><br><span class="line">2 layers + 8 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 8 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 8 kicks : 2999 / 3000 = 99%</span><br><span class="line">2 layers + 9 kicks : 2703 / 3000 = 90%</span><br><span class="line">3 layers + 9 kicks : 2836 / 3000 = 94%</span><br><span class="line">3 virtual layers + 9 kicks : 2999 / 3000 = 99%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 2649 / 3500 = 75%</span><br><span class="line">2 layers + 1 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 1 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 1 kicks : 3440 / 3500 = 98%</span><br><span class="line">2 layers + 2 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 2 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 2 kicks : 3460 / 3500 = 98%</span><br><span class="line">2 layers + 3 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 3 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 3 kicks : 3469 / 3500 = 99%</span><br><span class="line">2 layers + 4 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 4 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 4 kicks : 3486 / 3500 = 99%</span><br><span class="line">2 layers + 5 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 5 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 5 kicks : 3490 / 3500 = 99%</span><br><span class="line">2 layers + 6 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 6 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 6 kicks : 3496 / 3500 = 99%</span><br><span class="line">2 layers + 7 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 7 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 7 kicks : 3495 / 3500 = 99%</span><br><span class="line">2 layers + 8 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 8 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 8 kicks : 3494 / 3500 = 99%</span><br><span class="line">2 layers + 9 kicks : 3088 / 3500 = 88%</span><br><span class="line">3 layers + 9 kicks : 3244 / 3500 = 92%</span><br><span class="line">3 virtual layers + 9 kicks : 3496 / 3500 = 99%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 2927 / 4000 = 73%</span><br><span class="line">2 layers + 1 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 1 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 1 kicks : 3883 / 4000 = 97%</span><br><span class="line">2 layers + 2 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 2 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 2 kicks : 3920 / 4000 = 98%</span><br><span class="line">2 layers + 3 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 3 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 3 kicks : 3943 / 4000 = 98%</span><br><span class="line">2 layers + 4 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 4 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 4 kicks : 3961 / 4000 = 99%</span><br><span class="line">2 layers + 5 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 5 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 5 kicks : 3972 / 4000 = 99%</span><br><span class="line">2 layers + 6 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 6 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 6 kicks : 3982 / 4000 = 99%</span><br><span class="line">2 layers + 7 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 7 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 7 kicks : 3988 / 4000 = 99%</span><br><span class="line">2 layers + 8 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 8 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 8 kicks : 3988 / 4000 = 99%</span><br><span class="line">2 layers + 9 kicks : 3401 / 4000 = 85%</span><br><span class="line">3 layers + 9 kicks : 3607 / 4000 = 90%</span><br><span class="line">3 virtual layers + 9 kicks : 3984 / 4000 = 99%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 3172 / 4500 = 70%</span><br><span class="line">2 layers + 1 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 1 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 1 kicks : 4280 / 4500 = 95%</span><br><span class="line">2 layers + 2 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 2 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 2 kicks : 4342 / 4500 = 96%</span><br><span class="line">2 layers + 3 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 3 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 3 kicks : 4382 / 4500 = 97%</span><br><span class="line">2 layers + 4 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 4 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 4 kicks : 4400 / 4500 = 97%</span><br><span class="line">2 layers + 5 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 5 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 5 kicks : 4426 / 4500 = 98%</span><br><span class="line">2 layers + 6 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 6 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 6 kicks : 4438 / 4500 = 98%</span><br><span class="line">2 layers + 7 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 7 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 7 kicks : 4460 / 4500 = 99%</span><br><span class="line">2 layers + 8 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 8 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 8 kicks : 4450 / 4500 = 98%</span><br><span class="line">2 layers + 9 kicks : 3709 / 4500 = 82%</span><br><span class="line">3 layers + 9 kicks : 3932 / 4500 = 87%</span><br><span class="line">3 virtual layers + 9 kicks : 4453 / 4500 = 98%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 3399 / 5000 = 67%</span><br><span class="line">2 layers + 1 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 1 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 1 kicks : 4628 / 5000 = 92%</span><br><span class="line">2 layers + 2 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 2 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 2 kicks : 4715 / 5000 = 94%</span><br><span class="line">2 layers + 3 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 3 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 3 kicks : 4773 / 5000 = 95%</span><br><span class="line">2 layers + 4 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 4 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 4 kicks : 4793 / 5000 = 95%</span><br><span class="line">2 layers + 5 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 5 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 5 kicks : 4809 / 5000 = 96%</span><br><span class="line">2 layers + 6 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 6 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 6 kicks : 4839 / 5000 = 96%</span><br><span class="line">2 layers + 7 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 7 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 7 kicks : 4856 / 5000 = 97%</span><br><span class="line">2 layers + 8 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 8 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 8 kicks : 4858 / 5000 = 97%</span><br><span class="line">2 layers + 9 kicks : 3971 / 5000 = 79%</span><br><span class="line">3 layers + 9 kicks : 4221 / 5000 = 84%</span><br><span class="line">3 virtual layers + 9 kicks : 4873 / 5000 = 97%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 3586 / 5500 = 65%</span><br><span class="line">2 layers + 1 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 1 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 1 kicks : 4928 / 5500 = 89%</span><br><span class="line">2 layers + 2 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 2 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 2 kicks : 5022 / 5500 = 91%</span><br><span class="line">2 layers + 3 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 3 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 3 kicks : 5085 / 5500 = 92%</span><br><span class="line">2 layers + 4 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 4 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 4 kicks : 5121 / 5500 = 93%</span><br><span class="line">2 layers + 5 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 5 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 5 kicks : 5133 / 5500 = 93%</span><br><span class="line">2 layers + 6 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 6 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 6 kicks : 5155 / 5500 = 93%</span><br><span class="line">2 layers + 7 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 7 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 7 kicks : 5192 / 5500 = 94%</span><br><span class="line">2 layers + 8 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 8 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 8 kicks : 5189 / 5500 = 94%</span><br><span class="line">2 layers + 9 kicks : 4220 / 5500 = 76%</span><br><span class="line">3 layers + 9 kicks : 4459 / 5500 = 81%</span><br><span class="line">3 virtual layers + 9 kicks : 5207 / 5500 = 94%</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">SimpleHashTable : 3773 / 6000 = 62%</span><br><span class="line">2 layers + 1 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 1 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 1 kicks : 5199 / 6000 = 86%</span><br><span class="line">2 layers + 2 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 2 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 2 kicks : 5272 / 6000 = 87%</span><br><span class="line">2 layers + 3 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 3 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 3 kicks : 5353 / 6000 = 89%</span><br><span class="line">2 layers + 4 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 4 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 4 kicks : 5379 / 6000 = 89%</span><br><span class="line">2 layers + 5 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 5 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 5 kicks : 5397 / 6000 = 89%</span><br><span class="line">2 layers + 6 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 6 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 6 kicks : 5423 / 6000 = 90%</span><br><span class="line">2 layers + 7 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 7 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 7 kicks : 5458 / 6000 = 90%</span><br><span class="line">2 layers + 8 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 8 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 8 kicks : 5473 / 6000 = 91%</span><br><span class="line">2 layers + 9 kicks : 4428 / 6000 = 73%</span><br><span class="line">3 layers + 9 kicks : 4692 / 6000 = 78%</span><br><span class="line">3 virtual layers + 9 kicks : 5483 / 6000 = 91%</span><br><span class="line">---</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hash Table 可能是最简单也性能最高的数据结构了. 但它有个问题叫做 Hash Collision(哈希碰撞). JVM 和 C++ STL 的做法是链表 Bucket, 还有个流派是 Open Addressing(开链). Cuckoo Hashing 是一种特殊的开链.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>最近的这一年</title>
    <link href="/2019/04/05/%E6%9C%80%E8%BF%91%E7%9A%84%E8%BF%99%E4%B8%80%E5%B9%B4/"/>
    <id>/2019/04/05/最近的这一年/</id>
    <published>2019-04-05T07:33:29.000Z</published>
    <updated>2019-04-14T18:41:04.829Z</updated>
    
    <content type="html"><![CDATA[<p>最近的这一年对我来说是非常神奇的一年. 大概有这么几件事.</p><ul><li><p>自立</p></li><li><p>加入了某站的在线存储组</p></li></ul><p>突然写 blog 是受了阿米老师的启发, Ta 每个月都会写总结, 看了什么, 学了什么. 在程序性能调优领域, 有句至理名言是&quot;If you cannot measure, you cannot optimize.&quot;. 我希望我遇到的这两件事不仅仅是写在这里当流水账, 也可以对我和正在读这篇文章的有缘人有益.</p><a id="more"></a><h2 id="自立"><a href="#自立" class="headerlink" title="自立"></a>自立</h2><p>自立真的是一件特别爽的事情! 以往和父母有争执, 无论谁对谁错, 当然了, 从传统孝的角度出发, 做子女都应该先认错, 但最后往往真正的原因都是口袋没钱了 / 肚子饿了 / 没地方去了, 乖乖地灰溜溜跑回家. 人望和平, 当备武力. 自立就是给了你一个核按钮(慎用)...</p><p>中国父母往往其实也挺看重独立的. 我爸小时候还经常批评我, 工作之后, 就只有问我工作累不累, 要多出去走走了. 我能有份正经工作, 没有不良嗜好, 身体没有病, 大富大贵看机遇, 小康生活应该是有了.</p><p>所以啊, 还在上学的小朋友们, 和父母吵架了, 能忍就忍吧. 反正你还是要吃饭的... 父母也不能说你一辈子. 上学买不起的东西, 那就工作了再买.</p><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><p>我在存储组干了半年多了, 名义上是 DevOps, 其实工作内容更多的是运维和客服, 兼职写些监控和脚本. 各路大佬都曾经说过 Ta 们的公司离破产只有很短的时间(30 天 ~ 3 个月). 我从我日常工作得出的结论是我离失业也只有 30 天.</p><p>我供职的公司对外宣布的用户数是一亿, 不小了吧? 从估值上看已经是大独角兽了. 但就架构来看, 开源全家桶完全 hold 得住. 那为什么不直接上云? 我维护的组件和 XX 云维护的组件有差别吗?</p><p>事实上, IaaS 应该已经很普遍了. 我司还有据我所知摩拜也是腾讯黑石服务器, 路由, 网络等硬件基础设施由云服务商提供. 逻辑还是一样的, A 司雇的小工装出来的服务器和 XX 云配的是没有差的, 上层跑得都是 Linux, 除非硬件配置不同. 云厂商却可以做到派人 24 小时值守, 动态退机器.</p><p>那么下一步是不是可以直接用云厂商的 MySQL, Kafka, Redis? 这也就是 SaaS 了. 我看新闻, Aurora 是 AWS 有史以来增长最快的云服务. 云绝对是一个铁杆庄稼, 只要啃得下去. 这个商业逻辑傻子也看得出来. 唯一的拦路虎只有价格, 但价格是会降的. 软件的边际成本接近于 0.</p><p>那么做业务是不是就高枕无忧呢? 相对来说, 虽然业务系统门槛低, 但需要的 Domain Knowledges 多, 确实不容易被替代. 现在又有了 AWS Lambda, 所谓 FaaS, 做业务系统的门槛进一步降低...</p><p>我对自身的规划是一定要往深里钻, 不要做在舒适区里摸鱼的运维. 既然基础设施迟早要定于云, 那我就要能做到给云提供基础设施!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近的这一年对我来说是非常神奇的一年. 大概有这么几件事.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;自立&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加入了某站的在线存储组&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;突然写 blog 是受了阿米老师的启发, Ta 每个月都会写总结, 看了什么, 学了什么. 在程序性能调优领域, 有句至理名言是&amp;quot;If you cannot measure, you cannot optimize.&amp;quot;. 我希望我遇到的这两件事不仅仅是写在这里当流水账, 也可以对我和正在读这篇文章的有缘人有益.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
