<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> mm_prefetch 与 mm_pause · 阿吉的博客</title><meta name="description" content="mm_prefetch 与 mm_pause - Jim Lin"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="/atom.xml" title="阿吉的博客"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">mm_prefetch 与 mm_pause</h1><div class="post-info">Oct 8, 2019</div><div class="post-content"><p>十一假期的最后一天的晚上睡不着, 才又想起了博客君... 这次要写的是 X86 的 mm_prefetch 和 mm_pause 指令. 这两个指令有共性也有相反的地方, 所以放在一起特别合适. 因为个人习惯, mm_prefetch 指令指使用 intrinsics 头文件后会生成的指令组, mm_pause 指令同理.</p>
<a id="more"></a>
<h2 id="mm-prefetch-与-mm-pause-的简单介绍"><a href="#mm-prefetch-与-mm-pause-的简单介绍" class="headerlink" title="mm_prefetch 与 mm_pause 的简单介绍"></a>mm_prefetch 与 mm_pause 的简单介绍</h2><p>mm_prefetch 和 mm_pause 都对于程序的正确性没有影响且对于 CPU 理论上只是一个 hint.</p>
<p>mm_prefetch 提示 CPU 要去预读取某些内存地址的内容到缓存中, 一般来说会拉一个 cache line(64B).</p>
<p>mm_pause 提示 CPU 要空转一会儿, 一般用于多核多线程场景下. 比如, 吃饭之前要做饭, 吃饭的人就必须等待做饭的人把饭做好才能吃, 等待这个动作就是 mm_pause 的功能.</p>
<p>可见以上两个指令是比较安全的, 但也不能滥用, 那么什么场景下最适合, 什么场景不能用呢?</p>
<h2 id="mm-prefetch"><a href="#mm-prefetch" class="headerlink" title="mm_prefetch"></a>mm_prefetch</h2><p>内存的延迟高达 70ns - 80ns, 一颗 2GHz 的处理器可以跑 140 - 160 个周期了. 这有多夸张呢? 一条 cache miss 的 MOV 指令顶得上百条普通的加法减法命令了... 以一当百就是这样了. 根据我实际的工程经验来看, 30% - 50% 的索引数据结构的耗时都在访问内存上. perf 中一看到单个函数内耗时 80% 的指令 99% 都是 MOV. 这个锅主要光速要背. 光 1us 只能跑 300 米左右, 1ns 只能跑 30厘米, 从 CPU 到内存那么多电路, 必然快不了.</p>
<p>那很自然的想法就是预读, 计算的时候后台拉内存, 还用吃饭的比方就是, 我在写代码的时候, 食堂已经在做饭了. CPU 就是这么做的, 这个叫 Hardware Prefetcher. CPU 会看有哪些 MOV 指令可以先做的, 就尽量做.</p>
<p>那为啥还要有 mm_prefetch 呢? 其实可以反问的是既然都有硬件预读器了, 为啥索引数据结构还有大量时间换在内存访问上呢? 因为显而易见的预读机会是不那么多的. 人一到点就吃饭, 这是一个规律的事件. 所以食堂大厨可以提前准备. 卖雨伞的摊贩就很难提前准备了. 这时候就有了软件预读, 也就是 mm_prefetch 指令. 程序员相比 CPU 有更详细的程序上下文信息来提前判断哪些内存可能会被用到.</p>
<p>如果只是科普下软件预读, 就很无聊了. 我在实践中发现 mm_prefetch 要起作用比想象中的难!</p>
<p>首先, 硬件预读已经能把显而易见的预读做完了, 到 pref 时发现 stall 的地方可能根本就不存在优化空间. 因为整个逻辑就是强前后相关的, 先种瓜才能得瓜.</p>
<p>其次, 由于硬件预读的逻辑不对程序员暴露, 加之现代处理器的黑科技特别多, 你很难 reason 每条指令究竟对整体运行时间有什么影响, 优化变成了排列组合然后编译运行计时的体力活.</p>
<p>想象有以下代码,</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> total = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    total += some_data[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我一开始想在 <code>total += some_data[i]</code> 时, 去预读 <code>some_data[i+1]</code> 会加速, 但现实是更慢了. 因为 CPU 太聪明了, 通过分支预测器, 它能大概率推断出执行完加法操作后, 会需要 <code>some_data[i+1]</code>, 从而让硬件预读器做了预读, 这时候 mm_prefetch 就是废指令. 但这个逻辑要生效必然是有条件的, 但这个是会随着处理器架构升级而变化的...</p>
<p>最后, 错误的 prefetch 会污染缓存, 把有用的数据逐出. 这个很好理解就不赘述了.</p>
<p>我总结出来的经验是不要把自己想得太聪明, 把处理器想得太笨. 比较稳妥的优化方案是找出因为 cache miss 而 stall 的点, 利用这个 stall 的时间做一些有用的事情而不是单纯想着消除这个 stall. 比如在 stall 点 A, 既然消除不了 A 的 stall, 那么我是不是可以在 A 点做一些计算? 拉内存不影响 CPU 做纯计算(在一定条件下). 这是废时间再利用策略, 我觉得很简单有效. 因为处理器都没辙了, 那些空闲的电路不用白不用. 我依靠这个策略提升了一个热点函数 10% 的性能.</p>
<h3 id="mm-prefetch-与软件超线程"><a href="#mm-prefetch-与软件超线程" class="headerlink" title="mm_prefetch 与软件超线程"></a>mm_prefetch 与软件超线程</h3><p>这是 mm_prefetch 的高阶用法, 但实用价值有限, 所以单独摘出来写, 权当开拓思路了. 超线程的实现机制简单说就是一个核心上面有两组一模一样的寄存器但共享计算单元(和一些别的单元), 这样对外暴露是多个核的样子. 一旦有一个核发生了 cache miss 或者别的 stall, 通过硬件电路在 ns 级别切换到这个核上的另一组寄存器, 那个寄存器下的工作就可以继续, 充分利用 CPU 上的空闲单元.</p>
<p>但一般来说 CPU 每个核只有 2 个线程, 还是有空闲的单元没用上呢? 如果 cache miss 很严重, 那每个核的超线程就应该更多, 反之如果基本没啥 cache miss, 超线程基本就是浪费. 硬件是改不了的, 所以只能折中, 选了个大多数情况下都不会差的每个核 2 个线程.</p>
<p>但其实软件是可以模拟超线程的, 一旦遇到了大概率会 cache miss 的点, 先用 mm_prefetch 预读, 然后执行下一个任务, 执行了一些任务后, 回到最初的那个任务, 大概率预读器也把内存读到缓存了, 继续执行, 没有 stall. 整体流程与硬件超线程如出一辙, 但由于是软件层面的, 可以做到单核 8 线程的效果, 甚至做单核 100 线程也没人拦着. 这个模型和协程非常契合.</p>
<p>由于 C++ 17 还没真正高性能的协程, 我用手写的状态机模拟了协程. 之前 Get 一次做一个操作, 现在改成 MultiGet, 一次拉 10 条, 等于有 10 个状态机, 来回轮转. 最后性能提升了令人震惊的 25%! 这个函数本来就高度优化了, 这真是在牙缝里扣的性能了.</p>
<p>总结下, 效果那么好, 但又说使用价值不高呢? 因为这要求调用方采用 MultiGet 而非 Get, 这个一般来说越上层的开发是越懒的... 为了 25% 的性能提升而彻底改变编程接口, 我只觉得有点难...</p>
<h3 id="mm-prefetch-的一点小瑕疵"><a href="#mm-prefetch-的一点小瑕疵" class="headerlink" title="mm_prefetch 的一点小瑕疵"></a>mm_prefetch 的一点小瑕疵</h3><p>mm_prefetch 严格来说是和硬件超线程冲突的, 因为硬件超线程就是为了解决 cache miss 而诞生的, 混用的时候建议多 bench. 我个人在多线程数据结构的情况下, 一般是不用 mm_prefetch 的.</p>
<h2 id="mm-pause"><a href="#mm-pause" class="headerlink" title="mm_pause"></a>mm_pause</h2><p>mm_pause 是为多核多线程而生的指令, 简单说就是让 CPU 啥是也不干. 但为啥这会对性能有好处呢?</p>
<ul>
<li>现代处理器有流水线和分支预测, 在 spin lock 的加锁过程中, 分支预测器会被训练成傻逼, 同时大量垃圾微指令塞满流水线.</li>
</ul>
<p>想象如下场景,</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (some_atomic_var.compare_exchange_weak(a, b)) &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>如果这个 <code>some_atomic_var</code> 一段时间内加锁不成功的话, 分支预测器会认定这个 loop 总是失败的, 这其实没有任何意义! 因为就算预测成功了, 也没有任何有意义的指令能够执行, 只能不断的 jump, jump, jump...</p>
<p>CPU 在硬件层面还是会 unroll loop 的, 然后一大堆 unroll 完的垃圾微指令会堆满流水线.</p>
<p>其实最好的策略就是 CPU 啥是也别干就老老实实等一会儿, 然后尝试 CAS 原子变量就好了.</p>
<ul>
<li>回退本身就能提高系统的吞吐</li>
</ul>
<p>10 个核 CAS 一个 bool 和 100 个核 CAS 一个 bool 在硬件层面显然前者更简单, 起码只 invalid 9 个 cache line 呢.</p>
<ul>
<li>mm_pause 可以让渡资源给别的超线程</li>
</ul>
<p>这是我从 folly 文档看来的, 原理上很容易理解, spin 的等待跟 cache miss 的 stall 差不多都是废时间.</p>
<p>我实践中的结果是 mm_pause 可以显著降低 spin 的次数, 之前要 spin 200 万次, 用了 mm_pause 之后就 20 万次左右. 但没有观察到显著的性能提升. 我推测是因为良好工况下, 多 spin 几次对于 CPU 来说不是不可接受的.</p>
<p>但是 mm_pause 让系统变稳定很多! 这个我没有算什么方差, 标准差, 但可以明显感觉出来. 我的 bench 一般 6 秒能跑完, 但有概率会跑到 9 秒, 用了 mm_pause 大部分情况下都能在 7 秒内完成.</p>
<p>总结, 我认为绝大多数的 spin lock 都应该用 mm_pause. 我是没遇到啥问题.</p>
</div></article></div></main><footer><div class="paginator"><a href="/2019/07/21/Go-Plan9-汇编与-Intel-TSX-指令集/" class="next">NEXT</a></div><div class="copyright"><p>© 2018 - 2019 <a href>Jim Lin</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script></body></html>