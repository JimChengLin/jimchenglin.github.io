<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> KV 存储引擎 · 阿吉的博客</title><meta name="description" content="KV 存储引擎 - Jim Lin"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="/atom.xml" title="阿吉的博客"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">KV 存储引擎</h1><div class="post-info">May 12, 2019</div><div class="post-content"><p>我这个周末都在被高等数学支配的恐惧中度过, (ノへ￣、) 写一篇我擅长方面的博文放松下, 希望能保持每周一更的频率. 什么 InnoDB, WiredTiger, LevelDB, RocksDB, 相关的文章有很多, 但为什么这些设计有道理呢? 我没有发现一篇讲得很明白.</p>
<a id="more"></a>
<h2 id="存储引擎是什么"><a href="#存储引擎是什么" class="headerlink" title="存储引擎是什么"></a>存储引擎是什么</h2><p>存储引擎听起来非常高大上, 其实干的事情真的很简单. 我写的第一个破百行的程序叫做 JPickle, J 是我英文名 Jim 的首字母, Pickle 代表着 Python 内置的序列化库 pickle. 它干了什么呢? 它可以实时序列化一个类 dict 的对象.</p>
<p>比如,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = JPickle(<span class="string">"/tmp/my_engine"</span>)</span><br><span class="line">a[<span class="string">'name'</span>] = <span class="string">'jim'</span></span><br></pre></td></tr></table></figure>
<p><code>name = jim</code> 这个信息就被存储到了 <code>/tmp/my_engine</code> 这个文件里, 下次只要再用 JPickle 打开同一个文件, 就可以读出 <code>name</code> 的值是 <code>jim</code>.</p>
<p>存储引擎是不是很简单? 做的事情在我看来就两件,</p>
<ul>
<li><p>维持一个映射关系, 比如 Key -&gt; Value, Key -&gt; Document</p>
</li>
<li><p>序列化并持久化映射</p>
</li>
</ul>
<p>Python 内置的 shelve 库也可以叫做一个存储引擎, 只是实现比较 naive. 现在想来当时的我也很 naive, 用着 Windows + Wing Python IDE + 微软雅黑. 槽点在于微软雅黑, 那时我觉得这世界上最好的编程字体就是它了吧. 直到很久之后我才发现等宽字体是多么的重要...</p>
<h2 id="存储引擎的实现"><a href="#存储引擎的实现" class="headerlink" title="存储引擎的实现"></a>存储引擎的实现</h2><h3 id="Python-shelve-库"><a href="#Python-shelve-库" class="headerlink" title="Python shelve 库"></a>Python shelve 库</h3><p>shelve 是没有硬盘索引概念的, 一切的映射都维护在一个字典里.</p>
<p>比如,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shelve</span><br><span class="line"></span><br><span class="line">d = shelve.open(filename) <span class="comment"># open -- file may get suffix added by low-level</span></span><br><span class="line">                          <span class="comment"># library</span></span><br><span class="line"></span><br><span class="line">d[key] = data   <span class="comment"># store data at key (overwrites old data if</span></span><br><span class="line">                <span class="comment"># using an existing key)</span></span><br><span class="line">data = d[key]   <span class="comment"># retrieve a COPY of data at key (raise KeyError if no</span></span><br><span class="line">                <span class="comment"># such key)</span></span><br><span class="line"><span class="keyword">del</span> d[key]      <span class="comment"># delete data stored at key (raises KeyError</span></span><br><span class="line">                <span class="comment"># if no such key)</span></span><br></pre></td></tr></table></figure>
<p><code>d[key] = data</code>, 实质上是把 data append 到某个文件, 然后把 data 在那个文件上 offset 以 <code>index[key] = data_offset</code> 的形式存在内存字典里.</p>
<p><code>data = d[key]</code> 的流程是从 index 读出 offset, 然后用 pickle.load 在文件的特定位置反序列化出 value 返回.</p>
<p>这种做法时兴叫做 <code>BitCask</code>, 即 key 和 offset 放内存, 再通过 offset 读硬盘得到 value. 说实话我不是很明白为什么这么简单的设计的冠名权给了 <code>BitCask</code>.</p>
<h2 id="JPickle"><a href="#JPickle" class="headerlink" title="JPickle"></a>JPickle</h2><p>这是我实现的库, 代码已经遗失了, 还挺可惜的. shelve 有两个重大的问题,</p>
<ul>
<li>shelve 没有断电保护</li>
</ul>
<p>当 <code>d[key] = data</code> 之后, 程序崩溃或者电脑断电了, shelve 的数据就丢了, 除非每次变更完都来一遍 <code>d.sync()</code>, 把 key -&gt; offset 的索引固化在硬盘上(value 已经是实时 append 的了). 所谓固化就是把整个索引重新 pickle.dump 一遍... 想象一下, 为了写 1KB 的数据, 就要重写 1MB 索引的可怕...</p>
<ul>
<li>shelve 没有垃圾回收</li>
</ul>
<p><code>del d[key]</code> 对于 shelve 来说是根本不回收硬盘空间的, 随着使用时间的增长, 空间占用快速单调递增.</p>
<p>我当时想得太多, 学得太少, 琢磨出了两个主意,</p>
<ul>
<li><p>每做一个变更, 我就把这个变更写进一个日志里, 然后即使断电了, 也可以通过回放日志来保持数据的安全性</p>
</li>
<li><p>建立一个垃圾回收的机制. 一旦有数据被删了, 就把被删掉的那个段标记为 dirty. 如果之后有数据刚好可以写进这个段, 就可以复用空间. 碎片化严重的话, 再进行完全重写.</p>
</li>
</ul>
<p>我实现完之后简直震惊了! Amazing! 我怎么这么厉害??? 我才初学编程就写出这么一个性能, 功能吊打标准库的程序, 我岂不是天才? 后来才发现想法一叫做 WAL(write ahead log), 想法二叫做 Compaction. 二者的年龄可能比我父母还大.</p>
<p>轮胎是圆的, 那是因为只能是圆的. 虽然流言终结者真的做过正方形轮胎... JPickle 已经具有了存储引擎的雏形了,</p>
<ul>
<li><p>一般的存储引擎都需要有一个 WAL / redo log 来确保操作的原子性和持久性</p>
</li>
<li><p>如果输入不是定长和定量的数据(99.9% 的情况), 存储空间的碎片化是不可避免的. 合格的存储引擎应该尽量回收碎片空间.</p>
</li>
</ul>
<h2 id="存储引擎索引"><a href="#存储引擎索引" class="headerlink" title="存储引擎索引"></a>存储引擎索引</h2><p>shelve, JPickle, BitCask 都选择了比较简单的索引实现, 索引整个都放在内存里. 但面对海量数据的时候, 很有可能索引是放不进内存里的, 所以必须要在硬盘上直接建立索引. 硬盘索引有两大家族.</p>
<h3 id="B-Tree-家族"><a href="#B-Tree-家族" class="headerlink" title="B-Tree 家族"></a>B-Tree 家族</h3><p>B-Tree 以及其变种如 B+-Tree 的算法流程可以自行了解. 其合理性在于硬盘, 无论是 HDD 还是 SSD 都是块设备, 一次读取最少读一块. HDD 一般是 512bytes, 称之为一个扇区(sector). SSD 则比较多样, 一般最少 4KB 称之为 page. 此外 HDD 还有很高的寻道时间, 一般在 10ms 左右.</p>
<p>因此对于硬盘来说, 读 8bytes 与读 4KB 是没有什么差别的. 将传统的红黑树 / AVL 树的小节点拍扁合并成接近硬盘块大小甚至更大的块的树就是 B-Tree. 千万级别的元素数量, 对于 B-Tree 来说, 只要跳转大约 4 次左右就够了. 换作二叉平衡树则要 20+ 次.</p>
<p>B-Tree 的最大深度为<br>\[ O(log_k n) \]</p>
<p>k 为单个 B-Tree 节点的 key 最大数量 / 2, 越大的 B-Tree 节点的 k 越大, 单节点读取时间越长, 但查询和修改需要跳转的次数越少. InnoDB 节点默认大小为 64KB.</p>
<p>B-Tree 索引也存在着相应的问题,</p>
<ul>
<li>写延迟与难以进行 Batch 优化</li>
</ul>
<p>假设要插入 key a, 在千万级别的 B-Tree 中大概率需要读 4 次节点, 以找到最接近 a 的已知 key. 一次写入操作 = 一次读取操作 + 可能的节点分裂 + 节点插入. 写速度恒 &lt;= 读速度. 这对于写多读少的场景, 比如 Google 的爬虫索引更新是不可接受的. 一个页面更新了, 搜索引擎并不需要立刻反应到搜索结果上, 更理想的是变更操作能攒起来, 然后大批量处理.</p>
<ul>
<li>写放大与 SSD 的随机写 GC</li>
</ul>
<p>B-Tree 节点内部一般是数组 + 二分查找实现的, 对节点的修改会导致整个节点重写, 这就有写放大. 情况在 SSD 时代更加严重, SSD 没有覆写操作. 只能先擦除一整个 block(一般包含 16 个 page), 然后再回写. 为了优化覆写的性能, SSD 有可能直接将数据写入一个新的空白块, 之前的块标记为脏, 等待后续的 GC. 当随机写越来越多时, GC 跟不上就会造成性能骤降. 我自己测试出来的结果是顺序写的吞吐可以到 2GB/s, 随机写在 GC 严重时只有 400MB/s.</p>
<ul>
<li>难以实现快照机制</li>
</ul>
<p>B-Tree 并不是一个 append-only 的数据结构, 只能用 COW(copy on write) 的方式实现快照, 这成本很高.</p>
<ul>
<li>空间利用率低</li>
</ul>
<p>传统 B-Tree 只能保证至少 1/2 的空间是被利用的.</p>
<h3 id="LSMT-家族"><a href="#LSMT-家族" class="headerlink" title="LSMT 家族"></a>LSMT 家族</h3><p>LSMT 是 Log-Structured Merge Tree 的缩写, 代表是由 Google 传奇程序员 Jeff Dean 实现的 LevelDB. LevelDB 是 Google GFS / BigTable 的基石. 相比于 197X 年就提出的 B-Tree, LSMT 大约在 2000 年才有了第一个可靠的实现(LevelDB).</p>
<p>究其原因, 我认为是 LSMT 在理论上先天是不美的, 这是一个工程师才会喜欢的数据结构. 简单概括下逻辑就是放弃数据的全局有序性, 只确保在某一块内的数据有序, 通过限制 key 区间重叠的块的数量来保证读取速度. 细节可以 wiki. 在最差情况下(输入的 key 都和现有块的区间重叠造成雪崩式 Compaction), LSMT 表现糟糕得一塌糊涂. 除此之外, LSMT 剩下的就都是优点了.</p>
<ul>
<li>逻辑简单, 分层清楚, 易于优化</li>
</ul>
<p>MemTable, IMMemTable, SSTable 可以看成三个独立的组件. Compaction 只需要处理 IMMemTable 和 SSTable 这种 immutable 的数据结构. 这个就好像 Raft v.s. Multi-Paxos. Raft 看似限制多, 但因为它实现简单, 工程师反而有更多的信心去优化.</p>
<ul>
<li>空间利用率高</li>
</ul>
<p>LSMT 会频繁 Compaction, 这样被删除的 key 占用的空间就得到了释放. 同时 SSTable 可以用更激进的块压缩(e.g. zstd)进一步节约空间.</p>
<ul>
<li>数据冷热分层, cache 利用率高</li>
</ul>
<p>数据天然存在时间和空间连续性. 热 key 一般在上层, cache 不容易 miss. 那么对于热 key 来说, 读很大概率都是 O(1) 的.</p>
<ul>
<li><p>无随机写, append-only</p>
</li>
<li><p>通过保证局部有序实现写操作无阻塞</p>
</li>
</ul>
<p>这个是 LSMT 的精髓. 对于全局有序的数据结构, 读和写是需要立刻完成的. LSMT 外加了一个 Compaction 操作, 使得写不再依赖读了, 达成无阻塞. Compaction 成了一个平衡读写性能的中间操作. 根据场景不同, LSMT 可以用不同的 Compaction 参数. 比如, 读很重要, 那么就可以提升 Compaction 的频率.</p>
<h2 id="读写引擎的未来"><a href="#读写引擎的未来" class="headerlink" title="读写引擎的未来"></a>读写引擎的未来</h2><p>由于有 RocksDB 这个优秀的开源 LSMT KV 存储引擎实现, 使用 RocksDB 基本上已经是开源社区的主流选择了, 比如 TiKV, CockroachDB, Pika. 但是不是 RocksDB 就没别的读写引擎能挑战了呢?</p>
<p>我觉得不是的. 一些 LSMT 很科学的假设在飞速发展的存储技术面前已经有些失效了.</p>
<ul>
<li><p>随机读比顺序读慢很多 ❎ Intel P4510 4 KB 随机吞吐 2.5 GB/s, 64 MB 顺序吞吐 2.9 GB/s</p>
</li>
<li><p>持久化 IO 设备不是 Byte-Addressable 的 ❎ NVM 与内存没有差别, 支持 load 与 store 操作</p>
</li>
</ul>
<p>新思路</p>
<ul>
<li><p>Wisckey, key 存储在 LSMT 中, value 存储在 value log 里, 充分利用 SSD 强悍的随机读取能力</p>
</li>
<li><p>BzTree, 直接在 NVM 上用 CAS 操作进行存储</p>
</li>
</ul>
<p>除了存储设备上的快速发展, RocksDB 本身的结构在云时代也存在许多局限.</p>
<ul>
<li><p>多租户 / QOS</p>
</li>
<li><p>多实例同步</p>
</li>
<li><p>多线程阻塞 IO 模型</p>
</li>
</ul>
<p>尤其是多线程阻塞 IO 模型, 这一定会导致 RocksDB 整个重写. 我自己测试 P4510, 阻塞 IO 需要 128 个线程才比得上 libaio 的 8 个线程, 而 Linux Kernel 5.1 又加入了 <strong>io_uring</strong>, 性能相对于 libaio 又大幅度提升. 或许等 Ubuntu / Debian 有 5.1 内核的 LTS 发行版的时候, 我就可以去创业了? 专做高性能 KV 存储🤔.</p>
</div></article></div></main><footer><div class="paginator"><a href="/2019/07/21/Go-Plan9-汇编与-Intel-TSX-指令集/" class="prev">PREV</a><a href="/2019/05/03/雾计算第一期-高中知识回顾/" class="next">NEXT</a></div><div class="copyright"><p>© 2018 - 2019 <a href>Jim Lin</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script></body></html>